{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC7NvG6PJSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b742ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.linspace(0, 3*np.pi, 500)\n",
    "plt.plot(x, np.sin(x**2))\n",
    "plt.title('A simple chirp');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=0 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=0 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=0 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=1 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=1 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=1 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=2 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=2 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=2 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=3 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=3 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=3 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=4 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=4 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=4 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=5 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=5 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=5 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=6 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=6 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=6 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=7 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=7 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=7 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=8 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=8 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=8 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=9 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=9 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=9 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=10 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=10 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=10 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=11 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=11 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=11 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=12 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=12 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=12 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=13 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=13 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=13 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=14 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=14 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=14 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=15 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=15 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=15 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=16 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=16 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=16 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=17 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=17 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=17 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=18 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=18 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=18 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=19 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=19 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=19 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=20 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=20 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=20 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=21 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=21 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=21 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=22 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=22 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=22 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=23 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=23 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=23 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=24 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=24 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=24 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=25 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=25 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=25 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=26 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=26 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=26 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=27 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=27 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=27 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=28 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=28 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=28 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=29 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=29 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=29 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=30 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=30 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=30 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=31 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=31 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=31 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=32 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=32 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=32 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=33 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=33 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=33 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=34 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=34 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=34 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=35 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=35 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=35 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=36 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=36 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=36 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=37 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=37 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=37 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=38 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=38 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=38 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=39 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=39 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=39 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=40 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=40 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=40 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=41 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=41 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=41 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=42 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=42 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=42 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=43 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=43 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=43 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=44 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=44 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=44 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=45 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=45 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=45 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=46 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=46 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=46 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=47 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=47 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=47 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=48 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=48 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=48 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=49 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=49 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=49 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=50 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=50 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=50 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=51 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=51 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=51 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=52 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=52 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=52 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=53 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=53 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=53 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=54 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=54 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=54 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=55 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=55 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=55 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=56 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=56 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=56 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=57 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=57 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=57 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=58 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=58 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=58 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=59 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=59 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=59 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=60 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=60 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=60 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=61 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=61 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=61 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=62 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=62 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=62 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=63 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=63 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=63 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=64 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=64 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=64 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"2\" n_features=2919 grp=65 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"2\" n_features=2919 grp=65 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"2\" n_features=2919 grp=65 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=66 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=66 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=66 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"1\" n_features=2919 grp=67 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"1\" n_features=2919 grp=67 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"1\" n_features=2919 grp=67 seq=0 fs_col=2>\n",
      "NEW FEATURE SPACE FROM FILE LIST: <FeatureSpace \"medial_7_6_8_delta_3bin\" n_features=8757 n_total_samples=68 n_samples_per_group=1 n_classes=3 samples_per_class=(\"0\": 28, \"1\": 28, \"2\": 12)>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from wndcharm.FeatureSpace import FeatureSpace\n",
    "f=FeatureSpace.NewFromFileOfFiles( os.path.expanduser('data/medial_7_6_8_delta_3bin.fof'), long=True )\n",
    "f.ToFitFile('data/medial_7_6_8_delta_3bin.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.46300000e+03   5.44220000e-02   2.34303000e-01 ...,  -4.20041000e+04\n",
      "    1.33342000e+05   7.16966000e-01]\n",
      " [  2.46100000e+03   3.82510000e-02   4.73540000e-02 ...,  -5.46250000e+04\n",
      "    1.36239000e+05   7.25326000e-01]\n",
      " [  2.46300000e+03   2.86680000e-02   2.27273000e-01 ...,  -3.12424000e+04\n",
      "    1.15157000e+05   7.13205000e-01]\n",
      " ..., \n",
      " [  2.40200000e+03   7.63360000e-02   1.62866000e-01 ...,  -6.03631000e+04\n",
      "    1.30804000e+05   7.21693000e-01]\n",
      " [  2.45000000e+03   1.28302000e-01   7.62710000e-02 ...,  -5.37427000e+04\n",
      "    1.35765000e+05   7.17335000e-01]\n",
      " [  2.43000000e+03   1.49250000e-02   4.86660000e-02 ...,  -4.15241000e+04\n",
      "    1.06458000e+05   7.17794000e-01]]\n",
      "[array([[  2.46300000e+03,   5.44220000e-02,   2.34303000e-01, ...,\n",
      "         -4.20041000e+04,   1.33342000e+05,   7.16966000e-01],\n",
      "       [  2.46100000e+03,   3.82510000e-02,   4.73540000e-02, ...,\n",
      "         -5.46250000e+04,   1.36239000e+05,   7.25326000e-01],\n",
      "       [  2.46300000e+03,   2.86680000e-02,   2.27273000e-01, ...,\n",
      "         -3.12424000e+04,   1.15157000e+05,   7.13205000e-01],\n",
      "       ..., \n",
      "       [  2.46000000e+03,   9.27490000e-02,   1.09422000e-01, ...,\n",
      "         -4.05947000e+04,   1.11102000e+05,   7.22446000e-01],\n",
      "       [  2.46800000e+03,   5.57620000e-02,   4.00000000e-02, ...,\n",
      "         -5.21063000e+04,   1.32438000e+05,   7.16579000e-01],\n",
      "       [  2.46300000e+03,   2.09520000e-02,   1.38211000e-01, ...,\n",
      "         -5.16194000e+04,   1.38129000e+05,   7.18402000e-01]]), array([[  2.47100000e+03,   9.96700000e-03,   9.09090000e-02, ...,\n",
      "         -5.68879000e+04,   1.24726000e+05,   7.11482000e-01],\n",
      "       [  2.46700000e+03,   8.28920000e-02,   4.14750000e-02, ...,\n",
      "         -5.34658000e+04,   1.29016000e+05,   7.17171000e-01],\n",
      "       [  2.30200000e+03,   8.79350000e-02,   1.46444000e-01, ...,\n",
      "         -6.22379000e+04,   1.28003000e+05,   7.28210000e-01],\n",
      "       ..., \n",
      "       [  2.39400000e+03,   7.52690000e-02,   1.33676000e-01, ...,\n",
      "         -6.33295000e+04,   1.29084000e+05,   7.18021000e-01],\n",
      "       [  2.45300000e+03,   9.92910000e-02,   1.74089000e-01, ...,\n",
      "         -6.37833000e+04,   1.18731000e+05,   7.15956000e-01],\n",
      "       [  2.47000000e+03,   4.04410000e-02,   1.94904000e-01, ...,\n",
      "         -6.39740000e+04,   1.28504000e+05,   7.26436000e-01]]), array([[  2.42200000e+03,   5.28110000e-02,   6.77970000e-02, ...,\n",
      "         -5.86787000e+04,   1.32068000e+05,   7.29644000e-01],\n",
      "       [  2.17300000e+03,   1.36719000e-01,   1.68450000e-02, ...,\n",
      "         -6.16052000e+04,   1.26405000e+05,   7.24288000e-01],\n",
      "       [  2.43200000e+03,   1.44312000e-01,   7.37460000e-02, ...,\n",
      "         -5.17925000e+04,   1.17332000e+05,   7.18500000e-01],\n",
      "       ..., \n",
      "       [  2.40200000e+03,   7.63360000e-02,   1.62866000e-01, ...,\n",
      "         -6.03631000e+04,   1.30804000e+05,   7.21693000e-01],\n",
      "       [  2.45000000e+03,   1.28302000e-01,   7.62710000e-02, ...,\n",
      "         -5.37427000e+04,   1.35765000e+05,   7.17335000e-01],\n",
      "       [  2.43000000e+03,   1.49250000e-02,   4.86660000e-02, ...,\n",
      "         -4.15241000e+04,   1.06458000e+05,   7.17794000e-01]])]\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '2', '2', '2', '1', '1', '1', '2', '1', '1']\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "dmat = f.ContiguousDataMatrix()\n",
    "print (dmat)\n",
    "print (f.data_list)\n",
    "print (f._contiguous_ground_truth_labels)\n",
    "print (f._contiguous_ground_truth_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n",
      "[0.0, 1.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "print (f.class_names)\n",
    "class_vals = [float(x) for x in f.class_names]\n",
    "print (class_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.lda import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize (train, test):\n",
    "    norm_train_set = train.copy() \n",
    "    mins, maxs = normalize_by_columns (norm_train_set)\n",
    "    norm_test_set = test.copy() \n",
    "    normalize_by_columns (norm_test_set, mins, maxs)\n",
    "    return (norm_train_set, norm_test_set)\n",
    "\n",
    "def normalize_by_columns ( full_stack, mins = None, maxs = None ):\n",
    "    \"\"\"This is a global function to normalize a matrix by columns.\n",
    "    If numpy 1D arrays of mins and maxs are provided, the matrix will be normalized against these ranges\n",
    "    Otherwise, the mins and maxs will be determined from the matrix, and the matrix will be normalized\n",
    "    against itself. The mins and maxs will be returned as a tuple.\n",
    "    Out of range matrix values will be clipped to min and max (including +/- INF)\n",
    "    zero-range columns will be set to 0.\n",
    "    NANs in the columns will be set to 0.\n",
    "    The normalized output range is hard-coded to 0-100\n",
    "    \"\"\"\n",
    "    # Edge cases to deal with:\n",
    "    # Range determination:\n",
    "    # 1. features that are nan, inf, -inf\n",
    "    # max and min determination must ignore invalid numbers\n",
    "    # nan -> 0, inf -> max, -inf -> min\n",
    "    # Normalization:\n",
    "    # 2. feature values outside of range\n",
    "    # values clipped to range (-inf to min -> min, max to inf -> max) - leaves nan as nan\n",
    "    # 3. feature ranges that are 0 result in nan feature values\n",
    "    # 4. all nan feature values set to 0\n",
    "\n",
    "    # Turn off numpy warnings, since we're taking care of invalid values explicitly\n",
    "    oldsettings = np.seterr(all='ignore')\n",
    "    if (mins is None or maxs is None):\n",
    "        # mask out NANs and +/-INFs to compute min/max\n",
    "        full_stack_m = np.ma.masked_invalid (full_stack, copy=False)\n",
    "        maxs = full_stack_m.max (axis=0)\n",
    "        mins = full_stack_m.min (axis=0)\n",
    "\n",
    "    # clip the values to the min-max range (NANs are left, but +/- INFs are taken care of)\n",
    "    full_stack.clip (mins, maxs, full_stack)\n",
    "    # remake a mask to account for NANs and divide-by-zero from max == min\n",
    "    full_stack_m = np.ma.masked_invalid (full_stack, copy=False)\n",
    "\n",
    "    # Normalize\n",
    "    full_stack_m -= mins\n",
    "    full_stack_m /= (maxs - mins)\n",
    "    # Left over NANs and divide-by-zero from max == min become 0\n",
    "    # Note the deep copy to change the numpy parameter in-place.\n",
    "    full_stack[:] = full_stack_m.filled (0) * 100.0\n",
    "\n",
    "    # return settings to original\n",
    "    np.seterr(**oldsettings)\n",
    "\n",
    "    return (mins,maxs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stand (train, test):\n",
    "    scaler = StandardScaler()\n",
    "    new_train_set = scaler.fit_transform(train)\n",
    "    new_test_set = scaler.transform(test)\n",
    "    return (new_train_set,new_test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def round_robin_iteration (index, data_matrix_list):\n",
    "    '''Does a leave N out, where N is the number of classes.\n",
    "    The class with the smallest number of samples -1 (nsamples - 1) determines training set size.\n",
    "    Picks nsamples-1 for training and testing from a circular list starting at index.\n",
    "    Index ranges from 0 to the product of number of samples in each class.\n",
    "    data_matrix_list is a list of data matrixes, with one matrix per class'''\n",
    "    lengths = [m.shape[0] for m in data_matrix_list]\n",
    "    nclasses = len(lengths)\n",
    "    max_samples = min (lengths) - 1\n",
    "    indexes = [0] * nclasses\n",
    "    cl_index = index\n",
    "    for i in range (nclasses-1,0,-1):\n",
    "        indexes[i] = cl_index / lengths[i]\n",
    "        cl_index -= (indexes[i] * lengths[i])\n",
    "    indexes[0] = cl_index\n",
    "    indexes = list(reversed(indexes))\n",
    "    \n",
    "    train_mats = []\n",
    "    test_mats = []\n",
    "    for class_num in range(nclasses):\n",
    "        class_indexes = [ (count+indexes[class_num]+1) % lengths[class_num] for count in range (max_samples) ]\n",
    "        train_mats.append (np.take (data_matrix_list[class_num], class_indexes, axis=0) )\n",
    "        test_mats.append (np.take (data_matrix_list[class_num], [indexes[class_num]], axis=0) )\n",
    "    return (train_mats, test_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 0 0]\n",
      "  [1 1 1 1 1]\n",
      "  [2 2 2 2 2]\n",
      "  [3 3 3 3 3]\n",
      "  [4 4 4 4 4]\n",
      "  [5 5 5 5 5]\n",
      "  [6 6 6 6 6]\n",
      "  [7 7 7 7 7]]\n",
      "\n",
      " [[0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]]]\n",
      "-------\n",
      "[array([[2, 2, 2, 2, 2]]), array([[0, 1, 2, 3, 4]])]\n",
      "[array([[3, 3, 3, 3, 3],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [5, 5, 5, 5, 5],\n",
      "       [6, 6, 6, 6, 6],\n",
      "       [7, 7, 7, 7, 7],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1]]), array([[0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4]])]\n"
     ]
    }
   ],
   "source": [
    "dat_mat = np.mgrid[0:8,0:5]\n",
    "print (dat_mat)\n",
    "(train,test) = round_robin_iteration (19,dat_mat)\n",
    "print ('-------')\n",
    "print (test)\n",
    "print (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_contig_mat (data_matrix_list, class_vals):\n",
    "    data_mat_contig = np.vstack (data_matrix_list)\n",
    "    class_vals_vec_list = []\n",
    "    for class_idx in range (len(data_matrix_list)):\n",
    "        class_vals_vec_list += [class_vals[class_idx]] * len (data_matrix_list[class_idx])\n",
    "    class_vals_contig = np.asarray(class_vals_vec_list)\n",
    "    return (data_mat_contig,class_vals_contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Fisher(split):\n",
    "    \"\"\"Takes a FeatureSet_Discrete as input and calculates a Fisher score for\n",
    "    each feature. Returns a newly instantiated instance of FisherFeatureWeights.\n",
    "\n",
    "    For:\n",
    "    N = number of classes\n",
    "    F = number of features\n",
    "    It = total number of images in training set\n",
    "    Ic = number of images in a given class\n",
    "    \"\"\"\n",
    "\n",
    "    if split == None:\n",
    "        import inspect\n",
    "        form_str = 'You passed in a None as a training set to the function {0}.{1}'\t\n",
    "        raise ValueError( form_str.format( cls.__name__, inspect.stack()[1][3] ) )\n",
    "\n",
    "    # we deal with NANs/INFs separately, so turn off numpy warnings about invalid floats.\n",
    "    oldsettings = np.seterr(all='ignore')\n",
    "\n",
    "    def get_train_3d (self):\n",
    "        if self.train_3d is None:\n",
    "            self.train_3d = get_class_mat_list (self.train_set, self.train_classed_labels)\n",
    "        return (self.train_3d)\n",
    "\n",
    "    def get_test_3d (self):\n",
    "        if self.test_3d is None:\n",
    "            self.test_3d = get_class_mat_list (self.test_set, self.test_classed_labels)\n",
    "        return (self.test_3d)\n",
    "\n",
    "    #class_mats = split.get_train_3d()\n",
    "    class_mats = get_class_mat_list (split.train_set, split.train_classed_labels)\n",
    "    # 1D matrix 1 * F\n",
    "    population_means = np.mean( split.train_set, axis = 0 )\n",
    "    n_classes = class_mats.shape[0]\n",
    "    n_features = split.train_set.shape[1]\n",
    "\n",
    "    # 2D matrix shape N * F\n",
    "    intra_class_means = np.empty( [n_classes, n_features] )\n",
    "    # 2D matrix shape N * F\n",
    "    intra_class_variances = np.empty( [n_classes, n_features] )\n",
    "\n",
    "    class_index = 0\n",
    "    for class_feature_matrix in class_mats:\n",
    "        intra_class_means[ class_index ] = np.mean( class_feature_matrix, axis=0 )\n",
    "    # Note that by default, numpy divides by N instead of the more common N-1, hence ddof=1.\n",
    "        intra_class_variances[ class_index ] = np.var( class_feature_matrix, axis=0, ddof=1 )\n",
    "        class_index += 1\n",
    "\n",
    "    # 1D matrix 1 * F\n",
    "    # we deal with NANs/INFs separately, so turn off numpy warnings about invalid floats.\n",
    "    # for the record, in numpy:\n",
    "    # 1./0. = inf, 0./inf = 0., 1./inf = 0. inf/0. = inf, inf/inf = nan\n",
    "    # 0./0. = nan, nan/0. = nan, 0/nan = nan, nan/nan = nan, nan/inf = nan, inf/nan = nan\n",
    "    # We can't deal with NANs only, must also deal with pos/neg infs\n",
    "    # The masked array allows for dealing with \"invalid\" floats, which includes nan and +/-inf\n",
    "    denom = np.mean( intra_class_variances, axis = 0 )\n",
    "    denom[denom == 0] = np.nan\n",
    "    feature_weights_m = np.ma.masked_invalid (\n",
    "            ( np.square( population_means - intra_class_means ).sum( axis = 0 ) /\n",
    "        (n_classes - 1) ) / denom\n",
    "        )\n",
    "    # return numpy error settings to original\n",
    "    np.seterr(**oldsettings)\n",
    "\n",
    "    # the filled(0) method of the masked array sets all nan and infs to 0\n",
    "    fisher_values = feature_weights_m.filled(0).tolist()\n",
    "\n",
    "    return (fisher_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pearson(train_mat, train_vals):\n",
    "    \"\"\"Calculate regression parameters and correlation statistics that fully define\n",
    "    a continuous classifier.\n",
    "\n",
    "    At present the feature weights are proportional the Pearson correlation coefficient\n",
    "    for each given feature.\"\"\"\n",
    "\n",
    "    from scipy import stats\n",
    "\n",
    "    # Known issue: running stats.linregress() with np.seterr (all='raise') has caused\n",
    "    # arithmetic underflow (FloatingPointError: 'underflow encountered in stdtr' )\n",
    "    # I think this is something we can safely ignore in this function, and return settings\n",
    "    # back to normal at the end. -CEC\n",
    "    np.seterr (under='ignore')    \n",
    "\n",
    "    pearson_coeffs = np.zeros(train_mat.shape[1])\n",
    "\n",
    "    for feature_index in range( train_mat.shape[1] ):\n",
    "        slope, intercept, pearson_coeff, p_value, std_err = stats.linregress(\n",
    "            train_vals, train_mat[:,feature_index]\n",
    "        )\n",
    "\n",
    "        pearson_coeffs[feature_index] = pearson_coeff\n",
    "# We're just returning the pearsons^2 now...\n",
    "#    pearson_values = [val*val / r_val_squared_sum for val in pearson_coeffs ]\n",
    "#    pearson_coeffs = (pearson_coeffs * pearson_coeffs) / r_val_squared_sum\n",
    "    pearson_coeffs *= pearson_coeffs\n",
    "    \n",
    "\n",
    "    # Reset numpy\n",
    "    np.seterr (all='raise')\n",
    "\n",
    "    return pearson_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def marg_prob_to_pred_value (marg_probs, class_vals):\n",
    "    weighted = np.array(marg_probs)*np.array(class_vals)\n",
    "    return (np.sum(weighted))\n",
    "\n",
    "def WND5(contig_train_mat, contig_test_mat, contig_train_vals):\n",
    "    n_test_samples = contig_test_mat.shape[0]\n",
    "    n_train_samples = contig_train_mat.shape[0]\n",
    "    predicted_classes = np.zeros(n_test_samples)\n",
    "    predicted_values = np.zeros(n_test_samples)\n",
    "    \n",
    "    epsilon = np.finfo( np.float ).eps\n",
    "    testimg_idx = 0\n",
    "    trainimg_idx = 0\n",
    "    \n",
    "    for testimg_idx in range( n_test_samples ):\n",
    "        # initialize\n",
    "        class_dists = {}\n",
    "        class_counts = {}\n",
    "        classnames_list = []\n",
    "\n",
    "        for trainimg_idx in range( n_train_samples ):\n",
    "            train_class_label = contig_train_vals[trainimg_idx]\n",
    "            if not train_class_label in class_dists:\n",
    "                class_dists [train_class_label] = 0.0\n",
    "                class_counts[train_class_label] = 0.0\n",
    "                classnames_list.append (train_class_label)\n",
    "\n",
    "            dists = np.absolute (contig_train_mat [trainimg_idx] - contig_test_mat [testimg_idx])\n",
    "            w_dist = np.sum( dists )\n",
    "            if w_dist > epsilon:\n",
    "                class_counts[train_class_label] += 1.0\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            w_dist = np.sum( np.square( dists ) )\n",
    "            # The exponent -5 is the \"5\" in \"WND5\"\n",
    "            class_dists[ train_class_label ] += w_dist ** -5\n",
    "\n",
    "        \n",
    "        class_idx = 0\n",
    "        class_similarities = [0]*len(class_dists)\n",
    "        for class_label in classnames_list:\n",
    "            class_similarities[class_idx] = class_dists[class_label] / class_counts[class_label]\n",
    "            class_idx += 1\n",
    "\n",
    "        norm_factor = sum( class_similarities )\n",
    "        marg_probs = np.array( [ x / norm_factor for x in class_similarities ] )\n",
    "\n",
    "        predicted_class_idx = marg_probs.argmax()\n",
    "\n",
    "        predicted_classes[testimg_idx] = classnames_list[ predicted_class_idx ]\n",
    "        predicted_values[testimg_idx] = marg_prob_to_pred_value (marg_probs, classnames_list)\n",
    "\n",
    "    return (predicted_classes, predicted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_by_weight (the_mat, feature_weights):\n",
    "    i = np.argsort(feature_weights)\n",
    "    sort_mat = the_mat[:,i]\n",
    "    sort_mat = np.fliplr(sort_mat)\n",
    "    return (sort_mat)\n",
    "\n",
    "def weigh_sort(train, test, feature_weights):\n",
    "    weigh_train = np.multiply (norm_train, feature_weights)\n",
    "    weigh_test = np.multiply (norm_test, feature_weights)\n",
    "\n",
    "    sorted_train = sort_by_weight (weigh_train, feature_weights)\n",
    "    sorted_test = sort_by_weight (weigh_test, feature_weights)\n",
    "    return (sorted_train, sorted_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand_forest_clf (contig_train_mat, contig_test_mat, contig_train_vals, rnd_state = None):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators = 30, random_state = rnd_state)\n",
    "    clf.fit(contig_train_mat, contig_train_vals)\n",
    "    predicted_classes = clf.predict(contig_test_mat)\n",
    "    return (predicted_classes)\n",
    "def rand_forest_reg (contig_train_mat, contig_test_mat, contig_train_vals, rnd_state = None):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    forest = RandomForestRegressor(n_estimators=30, random_state = rnd_state)\n",
    "    forest.fit(contig_train_mat, contig_train_vals)\n",
    "    predicted = forest.predict(contig_test_mat)\n",
    "    return (predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(contig_train_mat, contig_test_mat, contig_train_vals):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(contig_train_mat, contig_train_vals)\n",
    "    predicted = lin_reg.predict(contig_test_mat)\n",
    "    return (predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class sizes : [11, 11, 11]\n",
      "Features          : 200\n",
      "Iterations        : 9408\n",
      "Iteration 0; Predictions: [ 0.  2.  0.]; cumulative accuracies: [1.0, 0.0, 0.0]\n",
      "Iteration 1; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.0]\n",
      "Iteration 2; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.0]\n",
      "Iteration 3; Predictions: [ 0.  2.  0.]; cumulative accuracies: [1.0, 0.0, 0.0]\n",
      "Iteration 4; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.0]\n",
      "Iteration 5; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.0]\n",
      "Iteration 6; Predictions: [ 0.  2.  2.]; cumulative accuracies: [1.0, 0.0, 0.14285714285714285]\n",
      "Iteration 7; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.125]\n",
      "Iteration 8; Predictions: [ 0.  2.  0.]; cumulative accuracies: [1.0, 0.0, 0.1111111111111111]\n",
      "Iteration 9; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.1]\n",
      "Iteration 10; Predictions: [ 0.  2.  2.]; cumulative accuracies: [1.0, 0.0, 0.18181818181818182]\n",
      "Iteration 11; Predictions: [ 0.  2.  2.]; cumulative accuracies: [1.0, 0.0, 0.25]\n",
      "Iteration 12; Predictions: [ 0.  2.  0.]; cumulative accuracies: [1.0, 0.0, 0.23076923076923078]\n",
      "Iteration 13; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.21428571428571427]\n",
      "Iteration 14; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.2]\n",
      "Iteration 15; Predictions: [ 0.  2.  0.]; cumulative accuracies: [1.0, 0.0, 0.1875]\n",
      "Iteration 16; Predictions: [ 0.  2.  0.]; cumulative accuracies: [1.0, 0.0, 0.17647058823529413]\n",
      "Iteration 17; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.16666666666666666]\n",
      "Iteration 18; Predictions: [ 0.  2.  2.]; cumulative accuracies: [1.0, 0.0, 0.21052631578947367]\n",
      "Iteration 19; Predictions: [ 0.  2.  2.]; cumulative accuracies: [1.0, 0.0, 0.25]\n",
      "Iteration 20; Predictions: [ 0.  2.  0.]; cumulative accuracies: [1.0, 0.0, 0.23809523809523808]\n",
      "Iteration 21; Predictions: [ 0.  2.  1.]; cumulative accuracies: [1.0, 0.0, 0.22727272727272727]\n",
      "Iteration 22; Predictions: [ 0.  2.  2.]; cumulative accuracies: [1.0, 0.0, 0.2608695652173913]\n",
      "Iteration 23; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.9583333333333334, 0.0, 0.2916666666666667]\n",
      "Iteration 24; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.96, 0.0, 0.28]\n",
      "Iteration 25; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9615384615384616, 0.0, 0.2692307692307692]\n",
      "Iteration 26; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9629629629629629, 0.0, 0.25925925925925924]\n",
      "Iteration 27; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9642857142857143, 0.0, 0.25]\n",
      "Iteration 28; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9655172413793104, 0.0, 0.2413793103448276]\n",
      "Iteration 29; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9666666666666667, 0.0, 0.23333333333333334]\n",
      "Iteration 30; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.967741935483871, 0.0, 0.25806451612903225]\n",
      "Iteration 31; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.96875, 0.0, 0.25]\n",
      "Iteration 32; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.9696969696969697, 0.0, 0.24242424242424243]\n",
      "Iteration 33; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9705882352941176, 0.0, 0.23529411764705882]\n",
      "Iteration 34; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.9428571428571428, 0.0, 0.2571428571428571]\n",
      "Iteration 35; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.9444444444444444, 0.0, 0.2777777777777778]\n",
      "Iteration 36; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.9459459459459459, 0.0, 0.2702702702702703]\n",
      "Iteration 37; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9473684210526315, 0.0, 0.2631578947368421]\n",
      "Iteration 38; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9487179487179487, 0.0, 0.2564102564102564]\n",
      "Iteration 39; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.95, 0.0, 0.25]\n",
      "Iteration 40; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9512195121951219, 0.0, 0.24390243902439024]\n",
      "Iteration 41; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9523809523809523, 0.0, 0.23809523809523808]\n",
      "Iteration 42; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.9534883720930233, 0.0, 0.2558139534883721]\n",
      "Iteration 43; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9545454545454546, 0.0, 0.25]\n",
      "Iteration 44; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.9555555555555556, 0.0, 0.24444444444444444]\n",
      "Iteration 45; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9565217391304348, 0.0, 0.2391304347826087]\n",
      "Iteration 46; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9574468085106383, 0.0, 0.23404255319148937]\n",
      "Iteration 47; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.9583333333333334, 0.0, 0.25]\n",
      "Iteration 48; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.9387755102040817, 0.0, 0.24489795918367346]\n",
      "Iteration 49; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.92, 0.0, 0.24]\n",
      "Iteration 50; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.9215686274509803, 0.0, 0.23529411764705882]\n",
      "Iteration 51; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.9038461538461539, 0.0, 0.23076923076923078]\n",
      "Iteration 52; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.8867924528301887, 0.0, 0.22641509433962265]\n",
      "Iteration 53; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.8888888888888888, 0.0, 0.2222222222222222]\n",
      "Iteration 54; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.8909090909090909, 0.0, 0.23636363636363636]\n",
      "Iteration 55; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.8928571428571429, 0.0, 0.23214285714285715]\n",
      "Iteration 56; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.8771929824561403, 0.0, 0.22807017543859648]\n",
      "Iteration 57; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.8793103448275862, 0.0, 0.22413793103448276]\n",
      "Iteration 58; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.8813559322033898, 0.0, 0.22033898305084745]\n",
      "Iteration 59; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.8833333333333333, 0.0, 0.23333333333333334]\n",
      "Iteration 60; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.8688524590163934, 0.0, 0.22950819672131148]\n",
      "Iteration 61; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.8548387096774194, 0.0, 0.22580645161290322]\n",
      "Iteration 62; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.8412698412698413, 0.0, 0.2222222222222222]\n",
      "Iteration 63; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.828125, 0.0, 0.21875]\n",
      "Iteration 64; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.8153846153846154, 0.0, 0.2153846153846154]\n",
      "Iteration 65; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.803030303030303, 0.0, 0.21212121212121213]\n",
      "Iteration 66; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.7910447761194029, 0.0, 0.22388059701492538]\n",
      "Iteration 67; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.7794117647058824, 0.0, 0.23529411764705882]\n",
      "Iteration 68; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.7681159420289855, 0.014492753623188406, 0.2318840579710145]\n",
      "Iteration 69; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.7571428571428571, 0.014285714285714285, 0.22857142857142856]\n",
      "Iteration 70; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.7464788732394366, 0.014084507042253521, 0.23943661971830985]\n",
      "Iteration 71; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.7361111111111112, 0.013888888888888888, 0.25]\n",
      "Iteration 72; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.7397260273972602, 0.0136986301369863, 0.2465753424657534]\n",
      "Iteration 73; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.7432432432432432, 0.013513513513513514, 0.24324324324324326]\n",
      "Iteration 74; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.7466666666666667, 0.013333333333333334, 0.24]\n",
      "Iteration 75; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.75, 0.013157894736842105, 0.23684210526315788]\n",
      "Iteration 76; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.7532467532467533, 0.012987012987012988, 0.23376623376623376]\n",
      "Iteration 77; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.7564102564102564, 0.01282051282051282, 0.23076923076923078]\n",
      "Iteration 78; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.7468354430379747, 0.012658227848101266, 0.22784810126582278]\n",
      "Iteration 79; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.75, 0.0125, 0.225]\n",
      "Iteration 80; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.7530864197530864, 0.012345679012345678, 0.2222222222222222]\n",
      "Iteration 81; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.7560975609756098, 0.012195121951219513, 0.21951219512195122]\n",
      "Iteration 82; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.7590361445783133, 0.012048192771084338, 0.21686746987951808]\n",
      "Iteration 83; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.7619047619047619, 0.011904761904761904, 0.2261904761904762]\n",
      "Iteration 84; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.7529411764705882, 0.011764705882352941, 0.2235294117647059]\n",
      "Iteration 85; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.7441860465116279, 0.011627906976744186, 0.22093023255813954]\n",
      "Iteration 86; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.735632183908046, 0.011494252873563218, 0.21839080459770116]\n",
      "Iteration 87; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.7272727272727273, 0.011363636363636364, 0.2159090909090909]\n",
      "Iteration 88; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.7191011235955056, 0.011235955056179775, 0.21348314606741572]\n",
      "Iteration 89; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.7111111111111111, 0.011111111111111112, 0.2111111111111111]\n",
      "Iteration 90; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.7032967032967034, 0.01098901098901099, 0.21978021978021978]\n",
      "Iteration 91; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.6956521739130435, 0.010869565217391304, 0.22826086956521738]\n",
      "Iteration 92; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.6881720430107527, 0.010752688172043012, 0.22580645161290322]\n",
      "Iteration 93; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6808510638297872, 0.010638297872340425, 0.22340425531914893]\n",
      "Iteration 94; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.6736842105263158, 0.010526315789473684, 0.23157894736842105]\n",
      "Iteration 95; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.6666666666666666, 0.010416666666666666, 0.23958333333333334]\n",
      "Iteration 96; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.6701030927835051, 0.010309278350515464, 0.23711340206185566]\n",
      "Iteration 97; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.673469387755102, 0.01020408163265306, 0.23469387755102042]\n",
      "Iteration 98; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6767676767676768, 0.010101010101010102, 0.23232323232323232]\n",
      "Iteration 99; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.68, 0.01, 0.23]\n",
      "Iteration 100; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6831683168316832, 0.009900990099009901, 0.22772277227722773]\n",
      "Iteration 101; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6862745098039216, 0.00980392156862745, 0.22549019607843138]\n",
      "Iteration 102; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.6893203883495146, 0.009708737864077669, 0.23300970873786409]\n",
      "Iteration 103; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6923076923076923, 0.009615384615384616, 0.23076923076923078]\n",
      "Iteration 104; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.6952380952380952, 0.009523809523809525, 0.22857142857142856]\n",
      "Iteration 105; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6981132075471698, 0.009433962264150943, 0.22641509433962265]\n",
      "Iteration 106; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.7009345794392523, 0.009345794392523364, 0.2336448598130841]\n",
      "Iteration 107; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.7037037037037037, 0.009259259259259259, 0.24074074074074073]\n",
      "Iteration 108; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.7064220183486238, 0.009174311926605505, 0.23853211009174313]\n",
      "Iteration 109; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.7090909090909091, 0.00909090909090909, 0.23636363636363636]\n",
      "Iteration 110; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.7027027027027027, 0.009009009009009009, 0.23423423423423423]\n",
      "Iteration 111; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6964285714285714, 0.008928571428571428, 0.23214285714285715]\n",
      "Iteration 112; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.6902654867256637, 0.008849557522123894, 0.23008849557522124]\n",
      "Iteration 113; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6842105263157895, 0.008771929824561403, 0.22807017543859648]\n",
      "Iteration 114; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.6782608695652174, 0.008695652173913044, 0.23478260869565218]\n",
      "Iteration 115; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6724137931034483, 0.008620689655172414, 0.23275862068965517]\n",
      "Iteration 116; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.6666666666666666, 0.008547008547008548, 0.23076923076923078]\n",
      "Iteration 117; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6610169491525424, 0.00847457627118644, 0.2288135593220339]\n",
      "Iteration 118; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.6554621848739496, 0.008403361344537815, 0.23529411764705882]\n",
      "Iteration 119; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.65, 0.008333333333333333, 0.24166666666666667]\n",
      "Iteration 120; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.6528925619834711, 0.008264462809917356, 0.2396694214876033]\n",
      "Iteration 121; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.6557377049180327, 0.00819672131147541, 0.23770491803278687]\n",
      "Iteration 122; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6585365853658537, 0.008130081300813009, 0.23577235772357724]\n",
      "Iteration 123; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6612903225806451, 0.008064516129032258, 0.23387096774193547]\n",
      "Iteration 124; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.664, 0.008, 0.232]\n",
      "Iteration 125; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6666666666666666, 0.007936507936507936, 0.23015873015873015]\n",
      "Iteration 126; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.6692913385826772, 0.007874015748031496, 0.2283464566929134]\n",
      "Iteration 127; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.671875, 0.0078125, 0.2265625]\n",
      "Iteration 128; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.6744186046511628, 0.007751937984496124, 0.2248062015503876]\n",
      "Iteration 129; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.676923076923077, 0.007692307692307693, 0.2230769230769231]\n",
      "Iteration 130; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.6793893129770993, 0.007633587786259542, 0.22900763358778625]\n",
      "Iteration 131; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.6818181818181818, 0.007575757575757576, 0.23484848484848486]\n",
      "Iteration 132; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.6766917293233082, 0.007518796992481203, 0.23308270676691728]\n",
      "Iteration 133; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6716417910447762, 0.007462686567164179, 0.23134328358208955]\n",
      "Iteration 134; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.674074074074074, 0.007407407407407408, 0.22962962962962963]\n",
      "Iteration 135; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.6691176470588235, 0.007352941176470588, 0.22794117647058823]\n",
      "Iteration 136; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.6715328467153284, 0.0072992700729927005, 0.22627737226277372]\n",
      "Iteration 137; Predictions: [ 0.  0.  1.]; cumulative accuracies: [0.6739130434782609, 0.007246376811594203, 0.2246376811594203]\n",
      "Iteration 138; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.6690647482014388, 0.007194244604316547, 0.22302158273381295]\n",
      "Iteration 139; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.6714285714285714, 0.007142857142857143, 0.22142857142857142]\n",
      "Iteration 140; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.6666666666666666, 0.0070921985815602835, 0.2198581560283688]\n",
      "Iteration 141; Predictions: [ 0.  0.  1.]; cumulative accuracies: [0.6690140845070423, 0.007042253521126761, 0.21830985915492956]\n",
      "Iteration 142; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6643356643356644, 0.006993006993006993, 0.21678321678321677]\n",
      "Iteration 143; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.6597222222222222, 0.006944444444444444, 0.2152777777777778]\n",
      "Iteration 144; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.6551724137931034, 0.006896551724137931, 0.21379310344827587]\n",
      "Iteration 145; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6506849315068494, 0.00684931506849315, 0.21232876712328766]\n",
      "Iteration 146; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6462585034013606, 0.006802721088435374, 0.2108843537414966]\n",
      "Iteration 147; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6418918918918919, 0.006756756756756757, 0.20945945945945946]\n",
      "Iteration 148; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6375838926174496, 0.006711409395973154, 0.2080536912751678]\n",
      "Iteration 149; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6333333333333333, 0.006666666666666667, 0.20666666666666667]\n",
      "Iteration 150; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.6291390728476821, 0.006622516556291391, 0.2052980132450331]\n",
      "Iteration 151; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.625, 0.006578947368421052, 0.20394736842105263]\n",
      "Iteration 152; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.6209150326797386, 0.006535947712418301, 0.20261437908496732]\n",
      "Iteration 153; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6168831168831169, 0.006493506493506494, 0.2012987012987013]\n",
      "Iteration 154; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.6129032258064516, 0.0064516129032258064, 0.2]\n",
      "Iteration 155; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.6089743589743589, 0.00641025641025641, 0.1987179487179487]\n",
      "Iteration 156; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.6050955414012739, 0.006369426751592357, 0.19745222929936307]\n",
      "Iteration 157; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.6012658227848101, 0.006329113924050633, 0.1962025316455696]\n",
      "Iteration 158; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5974842767295597, 0.006289308176100629, 0.1949685534591195]\n",
      "Iteration 159; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.59375, 0.00625, 0.19375]\n",
      "Iteration 160; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.5900621118012422, 0.012422360248447204, 0.19254658385093168]\n",
      "Iteration 161; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5864197530864198, 0.012345679012345678, 0.19135802469135801]\n",
      "Iteration 162; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.588957055214724, 0.012269938650306749, 0.1901840490797546]\n",
      "Iteration 163; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.5853658536585366, 0.012195121951219513, 0.18902439024390244]\n",
      "Iteration 164; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.5818181818181818, 0.012121212121212121, 0.18787878787878787]\n",
      "Iteration 165; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5783132530120482, 0.012048192771084338, 0.18674698795180722]\n",
      "Iteration 166; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5748502994011976, 0.011976047904191617, 0.18562874251497005]\n",
      "Iteration 167; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.5714285714285714, 0.011904761904761904, 0.18452380952380953]\n",
      "Iteration 168; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5680473372781065, 0.011834319526627219, 0.1834319526627219]\n",
      "Iteration 169; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5647058823529412, 0.011764705882352941, 0.18235294117647058]\n",
      "Iteration 170; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5614035087719298, 0.011695906432748537, 0.18128654970760233]\n",
      "Iteration 171; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5581395348837209, 0.011627906976744186, 0.18023255813953487]\n",
      "Iteration 172; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5549132947976878, 0.011560693641618497, 0.1791907514450867]\n",
      "Iteration 173; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5517241379310345, 0.011494252873563218, 0.1781609195402299]\n",
      "Iteration 174; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.5485714285714286, 0.011428571428571429, 0.17714285714285713]\n",
      "Iteration 175; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5454545454545454, 0.011363636363636364, 0.17613636363636365]\n",
      "Iteration 176; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.5423728813559322, 0.011299435028248588, 0.1751412429378531]\n",
      "Iteration 177; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5393258426966292, 0.011235955056179775, 0.17415730337078653]\n",
      "Iteration 178; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.5363128491620112, 0.0111731843575419, 0.17318435754189945]\n",
      "Iteration 179; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.5333333333333333, 0.011111111111111112, 0.17222222222222222]\n",
      "Iteration 180; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.5303867403314917, 0.011049723756906077, 0.1712707182320442]\n",
      "Iteration 181; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.5274725274725275, 0.01098901098901099, 0.17032967032967034]\n",
      "Iteration 182; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.5245901639344263, 0.01092896174863388, 0.16939890710382513]\n",
      "Iteration 183; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.5217391304347826, 0.010869565217391304, 0.16847826086956522]\n",
      "Iteration 184; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.518918918918919, 0.010810810810810811, 0.16756756756756758]\n",
      "Iteration 185; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.5161290322580645, 0.010752688172043012, 0.16666666666666666]\n",
      "Iteration 186; Predictions: [ 1.  1.  0.]; cumulative accuracies: [0.5133689839572193, 0.016042780748663103, 0.1657754010695187]\n",
      "Iteration 187; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.5106382978723404, 0.02127659574468085, 0.16489361702127658]\n",
      "Iteration 188; Predictions: [ 2.  0.  0.]; cumulative accuracies: [0.5079365079365079, 0.021164021164021163, 0.164021164021164]\n",
      "Iteration 189; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.5052631578947369, 0.021052631578947368, 0.1631578947368421]\n",
      "Iteration 190; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.5026178010471204, 0.020942408376963352, 0.16230366492146597]\n",
      "Iteration 191; Predictions: [ 1.  1.  0.]; cumulative accuracies: [0.5, 0.026041666666666668, 0.16145833333333334]\n",
      "Iteration 192; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.5025906735751295, 0.025906735751295335, 0.16062176165803108]\n",
      "Iteration 193; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.5, 0.02577319587628866, 0.15979381443298968]\n",
      "Iteration 194; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.49743589743589745, 0.02564102564102564, 0.15897435897435896]\n",
      "Iteration 195; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.49489795918367346, 0.025510204081632654, 0.15816326530612246]\n",
      "Iteration 196; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.49238578680203043, 0.025380710659898477, 0.15736040609137056]\n",
      "Iteration 197; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4898989898989899, 0.025252525252525252, 0.15656565656565657]\n",
      "Iteration 198; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.49246231155778897, 0.02512562814070352, 0.15577889447236182]\n",
      "Iteration 199; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.49, 0.025, 0.155]\n",
      "Iteration 200; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.4925373134328358, 0.024875621890547265, 0.15422885572139303]\n",
      "Iteration 201; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4900990099009901, 0.024752475247524754, 0.15346534653465346]\n",
      "Iteration 202; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4876847290640394, 0.024630541871921183, 0.15270935960591134]\n",
      "Iteration 203; Predictions: [ 2.  2.  0.]; cumulative accuracies: [0.4852941176470588, 0.024509803921568627, 0.15196078431372548]\n",
      "Iteration 204; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.48292682926829267, 0.024390243902439025, 0.15121951219512195]\n",
      "Iteration 205; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.48058252427184467, 0.024271844660194174, 0.15048543689320387]\n",
      "Iteration 206; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4782608695652174, 0.024154589371980676, 0.1497584541062802]\n",
      "Iteration 207; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.47596153846153844, 0.02403846153846154, 0.14903846153846154]\n",
      "Iteration 208; Predictions: [ 2.  2.  2.]; cumulative accuracies: [0.47368421052631576, 0.023923444976076555, 0.15311004784688995]\n",
      "Iteration 209; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4714285714285714, 0.023809523809523808, 0.1523809523809524]\n",
      "Iteration 210; Predictions: [ 2.  2.  0.]; cumulative accuracies: [0.46919431279620855, 0.023696682464454975, 0.15165876777251186]\n",
      "Iteration 211; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4669811320754717, 0.02358490566037736, 0.1509433962264151]\n",
      "Iteration 212; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.4647887323943662, 0.023474178403755867, 0.15023474178403756]\n",
      "Iteration 213; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.46261682242990654, 0.02336448598130841, 0.14953271028037382]\n",
      "Iteration 214; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4604651162790698, 0.023255813953488372, 0.14883720930232558]\n",
      "Iteration 215; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.4583333333333333, 0.023148148148148147, 0.14814814814814814]\n",
      "Iteration 216; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.45622119815668205, 0.02304147465437788, 0.14746543778801843]\n",
      "Iteration 217; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.4541284403669725, 0.022935779816513763, 0.14678899082568808]\n",
      "Iteration 218; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4520547945205479, 0.0228310502283105, 0.1461187214611872]\n",
      "Iteration 219; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.45, 0.022727272727272728, 0.14545454545454545]\n",
      "Iteration 220; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.4479638009049774, 0.02262443438914027, 0.1493212669683258]\n",
      "Iteration 221; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.44594594594594594, 0.02252252252252252, 0.14864864864864866]\n",
      "Iteration 222; Predictions: [ 2.  2.  0.]; cumulative accuracies: [0.4439461883408072, 0.02242152466367713, 0.14798206278026907]\n",
      "Iteration 223; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4419642857142857, 0.022321428571428572, 0.14732142857142858]\n",
      "Iteration 224; Predictions: [ 2.  1.  0.]; cumulative accuracies: [0.44, 0.02666666666666667, 0.14666666666666667]\n",
      "Iteration 225; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.43805309734513276, 0.02654867256637168, 0.14601769911504425]\n",
      "Iteration 226; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.43612334801762115, 0.02643171806167401, 0.14537444933920704]\n",
      "Iteration 227; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.4342105263157895, 0.02631578947368421, 0.14473684210526316]\n",
      "Iteration 228; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.4366812227074236, 0.026200873362445413, 0.14410480349344978]\n",
      "Iteration 229; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.4391304347826087, 0.02608695652173913, 0.14347826086956522]\n",
      "Iteration 230; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.44155844155844154, 0.025974025974025976, 0.1471861471861472]\n",
      "Iteration 231; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.44396551724137934, 0.02586206896551724, 0.14655172413793102]\n",
      "Iteration 232; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.44635193133047213, 0.02575107296137339, 0.15021459227467812]\n",
      "Iteration 233; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.44871794871794873, 0.02564102564102564, 0.14957264957264957]\n",
      "Iteration 234; Predictions: [ 1.  1.  0.]; cumulative accuracies: [0.44680851063829785, 0.029787234042553193, 0.14893617021276595]\n",
      "Iteration 235; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.4491525423728814, 0.029661016949152543, 0.1483050847457627]\n",
      "Iteration 236; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.45147679324894513, 0.029535864978902954, 0.14767932489451477]\n",
      "Iteration 237; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.453781512605042, 0.029411764705882353, 0.14705882352941177]\n",
      "Iteration 238; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.4560669456066946, 0.029288702928870293, 0.1506276150627615]\n",
      "Iteration 239; Predictions: [ 0.  1.  0.]; cumulative accuracies: [0.4583333333333333, 0.03333333333333333, 0.15]\n",
      "Iteration 240; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.45643153526970953, 0.03319502074688797, 0.14937759336099585]\n",
      "Iteration 241; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.45454545454545453, 0.03305785123966942, 0.1487603305785124]\n",
      "Iteration 242; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.45267489711934156, 0.03292181069958848, 0.1522633744855967]\n",
      "Iteration 243; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.45081967213114754, 0.036885245901639344, 0.15163934426229508]\n",
      "Iteration 244; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.4489795918367347, 0.036734693877551024, 0.15510204081632653]\n",
      "Iteration 245; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.44715447154471544, 0.04065040650406504, 0.15447154471544716]\n",
      "Iteration 246; Predictions: [ 2.  1.  0.]; cumulative accuracies: [0.44534412955465585, 0.044534412955465584, 0.15384615384615385]\n",
      "Iteration 247; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.4435483870967742, 0.04838709677419355, 0.1532258064516129]\n",
      "Iteration 248; Predictions: [ 1.  0.  1.]; cumulative accuracies: [0.44176706827309237, 0.04819277108433735, 0.15261044176706828]\n",
      "Iteration 249; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.44, 0.048, 0.152]\n",
      "Iteration 250; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.43824701195219123, 0.04780876494023904, 0.1553784860557769]\n",
      "Iteration 251; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.4365079365079365, 0.047619047619047616, 0.15476190476190477]\n",
      "Iteration 252; Predictions: [ 2.  1.  1.]; cumulative accuracies: [0.43478260869565216, 0.05138339920948617, 0.1541501976284585]\n",
      "Iteration 253; Predictions: [ 2.  1.  1.]; cumulative accuracies: [0.4330708661417323, 0.05511811023622047, 0.15354330708661418]\n",
      "Iteration 254; Predictions: [ 2.  2.  2.]; cumulative accuracies: [0.43137254901960786, 0.054901960784313725, 0.1568627450980392]\n",
      "Iteration 255; Predictions: [ 2.  2.  0.]; cumulative accuracies: [0.4296875, 0.0546875, 0.15625]\n",
      "Iteration 256; Predictions: [ 2.  1.  2.]; cumulative accuracies: [0.4280155642023346, 0.058365758754863814, 0.15953307392996108]\n",
      "Iteration 257; Predictions: [ 2.  1.  1.]; cumulative accuracies: [0.4263565891472868, 0.06201550387596899, 0.15891472868217055]\n",
      "Iteration 258; Predictions: [ 2.  1.  0.]; cumulative accuracies: [0.4247104247104247, 0.06563706563706563, 0.1583011583011583]\n",
      "Iteration 259; Predictions: [ 2.  1.  1.]; cumulative accuracies: [0.4230769230769231, 0.06923076923076923, 0.1576923076923077]\n",
      "Iteration 260; Predictions: [ 2.  1.  0.]; cumulative accuracies: [0.421455938697318, 0.07279693486590039, 0.15708812260536398]\n",
      "Iteration 261; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4198473282442748, 0.07251908396946564, 0.15648854961832062]\n",
      "Iteration 262; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.41825095057034223, 0.07224334600760456, 0.155893536121673]\n",
      "Iteration 263; Predictions: [ 2.  2.  0.]; cumulative accuracies: [0.4166666666666667, 0.07196969696969698, 0.1553030303030303]\n",
      "Iteration 264; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.41509433962264153, 0.07169811320754717, 0.15471698113207547]\n",
      "Iteration 265; Predictions: [ 2.  1.  1.]; cumulative accuracies: [0.41353383458646614, 0.07518796992481203, 0.15413533834586465]\n",
      "Iteration 266; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.41198501872659177, 0.0749063670411985, 0.15355805243445692]\n",
      "Iteration 267; Predictions: [ 2.  2.  0.]; cumulative accuracies: [0.41044776119402987, 0.07462686567164178, 0.15298507462686567]\n",
      "Iteration 268; Predictions: [ 2.  2.  2.]; cumulative accuracies: [0.40892193308550184, 0.07434944237918216, 0.15613382899628253]\n",
      "Iteration 269; Predictions: [ 2.  1.  1.]; cumulative accuracies: [0.4074074074074074, 0.07777777777777778, 0.15555555555555556]\n",
      "Iteration 270; Predictions: [ 1.  1.  0.]; cumulative accuracies: [0.4059040590405904, 0.08118081180811808, 0.15498154981549817]\n",
      "Iteration 271; Predictions: [ 2.  1.  2.]; cumulative accuracies: [0.40441176470588236, 0.08455882352941177, 0.15808823529411764]\n",
      "Iteration 272; Predictions: [ 2.  1.  1.]; cumulative accuracies: [0.40293040293040294, 0.08791208791208792, 0.1575091575091575]\n",
      "Iteration 273; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.40145985401459855, 0.08759124087591241, 0.15693430656934307]\n",
      "Iteration 274; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4, 0.08727272727272728, 0.15636363636363637]\n",
      "Iteration 275; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.39855072463768115, 0.08695652173913043, 0.15579710144927536]\n",
      "Iteration 276; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3971119133574007, 0.08664259927797834, 0.1552346570397112]\n",
      "Iteration 277; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.39568345323741005, 0.08633093525179857, 0.15467625899280577]\n",
      "Iteration 278; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3942652329749104, 0.08602150537634409, 0.15412186379928317]\n",
      "Iteration 279; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.39285714285714285, 0.08571428571428572, 0.15357142857142858]\n",
      "Iteration 280; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3914590747330961, 0.08540925266903915, 0.15302491103202848]\n",
      "Iteration 281; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3900709219858156, 0.0851063829787234, 0.1524822695035461]\n",
      "Iteration 282; Predictions: [ 0.  1.  0.]; cumulative accuracies: [0.392226148409894, 0.08833922261484099, 0.1519434628975265]\n",
      "Iteration 283; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3908450704225352, 0.0880281690140845, 0.15140845070422534]\n",
      "Iteration 284; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.3894736842105263, 0.0912280701754386, 0.15087719298245614]\n",
      "Iteration 285; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3881118881118881, 0.09090909090909091, 0.15034965034965034]\n",
      "Iteration 286; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.3867595818815331, 0.09407665505226481, 0.14982578397212543]\n",
      "Iteration 287; Predictions: [ 1.  1.  1.]; cumulative accuracies: [0.3854166666666667, 0.09722222222222222, 0.14930555555555555]\n",
      "Iteration 288; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.3875432525951557, 0.09688581314878893, 0.14878892733564014]\n",
      "Iteration 289; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.3896551724137931, 0.09655172413793103, 0.1482758620689655]\n",
      "Iteration 290; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.3917525773195876, 0.09621993127147767, 0.14776632302405499]\n",
      "Iteration 291; Predictions: [ 0.  2.  0.]; cumulative accuracies: [0.3938356164383562, 0.0958904109589041, 0.14726027397260275]\n",
      "Iteration 292; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.39590443686006827, 0.09556313993174062, 0.14675767918088736]\n",
      "Iteration 293; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.3979591836734694, 0.09523809523809523, 0.14625850340136054]\n",
      "Iteration 294; Predictions: [ 0.  1.  0.]; cumulative accuracies: [0.4, 0.09830508474576272, 0.14576271186440679]\n",
      "Iteration 295; Predictions: [ 0.  1.  1.]; cumulative accuracies: [0.40202702702702703, 0.10135135135135136, 0.14527027027027026]\n",
      "Iteration 296; Predictions: [ 0.  1.  1.]; cumulative accuracies: [0.40404040404040403, 0.10437710437710437, 0.1447811447811448]\n",
      "Iteration 297; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.40604026845637586, 0.1040268456375839, 0.14429530201342283]\n",
      "Iteration 298; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.4080267558528428, 0.10367892976588629, 0.14381270903010032]\n",
      "Iteration 299; Predictions: [ 0.  1.  1.]; cumulative accuracies: [0.41, 0.10666666666666667, 0.14333333333333334]\n",
      "Iteration 300; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.40863787375415284, 0.10631229235880399, 0.14285714285714285]\n",
      "Iteration 301; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.40728476821192056, 0.10596026490066225, 0.1423841059602649]\n",
      "Iteration 302; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.40594059405940597, 0.10561056105610561, 0.1419141914191419]\n",
      "Iteration 303; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.40789473684210525, 0.10526315789473684, 0.14144736842105263]\n",
      "Iteration 304; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4065573770491803, 0.10491803278688525, 0.14098360655737704]\n",
      "Iteration 305; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.40522875816993464, 0.10457516339869281, 0.14052287581699346]\n",
      "Iteration 306; Predictions: [ 0.  1.  0.]; cumulative accuracies: [0.40716612377850164, 0.10749185667752444, 0.14006514657980457]\n",
      "Iteration 307; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.40584415584415584, 0.10714285714285714, 0.1396103896103896]\n",
      "Iteration 308; Predictions: [ 1.  0.  2.]; cumulative accuracies: [0.4045307443365696, 0.10679611650485436, 0.1423948220064725]\n",
      "Iteration 309; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.4032258064516129, 0.1064516129032258, 0.14193548387096774]\n",
      "Iteration 310; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.40192926045016075, 0.10610932475884244, 0.1414790996784566]\n",
      "Iteration 311; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.40064102564102566, 0.10576923076923077, 0.14423076923076922]\n",
      "Iteration 312; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3993610223642173, 0.10543130990415335, 0.14376996805111822]\n",
      "Iteration 313; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3980891719745223, 0.10509554140127389, 0.14331210191082802]\n",
      "Iteration 314; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3968253968253968, 0.10476190476190476, 0.14285714285714285]\n",
      "Iteration 315; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.39556962025316456, 0.10443037974683544, 0.14240506329113925]\n",
      "Iteration 316; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3943217665615142, 0.10410094637223975, 0.14195583596214512]\n",
      "Iteration 317; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.39308176100628933, 0.10377358490566038, 0.14150943396226415]\n",
      "Iteration 318; Predictions: [ 1.  1.  0.]; cumulative accuracies: [0.39184952978056425, 0.10658307210031348, 0.14106583072100312]\n",
      "Iteration 319; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.390625, 0.10625, 0.140625]\n",
      "Iteration 320; Predictions: [ 1.  0.  0.]; cumulative accuracies: [0.3894080996884735, 0.1059190031152648, 0.14018691588785046]\n",
      "Iteration 321; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.38819875776397517, 0.10559006211180125, 0.13975155279503104]\n",
      "Iteration 322; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.38699690402476783, 0.10526315789473684, 0.1393188854489164]\n",
      "Iteration 323; Predictions: [ 1.  2.  2.]; cumulative accuracies: [0.38580246913580246, 0.10493827160493827, 0.1419753086419753]\n",
      "Iteration 324; Predictions: [ 1.  2.  0.]; cumulative accuracies: [0.38461538461538464, 0.10461538461538461, 0.14153846153846153]\n",
      "Iteration 325; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3834355828220859, 0.10429447852760736, 0.1411042944785276]\n",
      "Iteration 326; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.382262996941896, 0.10397553516819572, 0.14067278287461774]\n",
      "Iteration 327; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.38109756097560976, 0.10365853658536585, 0.1402439024390244]\n",
      "Iteration 328; Predictions: [ 2.  2.  1.]; cumulative accuracies: [0.3799392097264438, 0.1033434650455927, 0.1398176291793313]\n",
      "Iteration 329; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.3787878787878788, 0.10303030303030303, 0.1393939393939394]\n",
      "Iteration 330; Predictions: [ 2.  2.  0.]; cumulative accuracies: [0.3776435045317221, 0.1027190332326284, 0.13897280966767372]\n",
      "Iteration 331; Predictions: [ 0.  2.  1.]; cumulative accuracies: [0.3795180722891566, 0.10240963855421686, 0.13855421686746988]\n",
      "Iteration 332; Predictions: [ 0.  0.  0.]; cumulative accuracies: [0.3813813813813814, 0.1021021021021021, 0.13813813813813813]\n",
      "Iteration 333; Predictions: [ 1.  2.  1.]; cumulative accuracies: [0.38023952095808383, 0.10179640718562874, 0.1377245508982036]\n",
      "Iteration 334; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.382089552238806, 0.10149253731343283, 0.14029850746268657]\n",
      "Iteration 335; Predictions: [ 0.  2.  2.]; cumulative accuracies: [0.38392857142857145, 0.10119047619047619, 0.14285714285714285]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 28 is out of bounds for size 28",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-82e028861e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miter_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mniter\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround_robin_iteration\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mcontig_train_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontig_train_vals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_to_contig_mat\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mcontig_test_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontig_test_vals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_to_contig_mat\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-0c2617258a85>\u001b[0m in \u001b[0;36mround_robin_iteration\u001b[0;34m(index, data_matrix_list)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclass_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_mats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_matrix_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtest_mats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_matrix_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_mats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(a, indices, axis, out, mode)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'take'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 28 is out of bounds for size 28"
     ]
    }
   ],
   "source": [
    "nfeatures = 200\n",
    "niter = np.product ( [m.shape[0] for m in f.data_list] )\n",
    "class_vals = [float(x) for x in f.class_names]\n",
    "n_correct = np.asarray( [0]*len(class_vals))\n",
    "(train,test) = round_robin_iteration (0,f.data_list)\n",
    "print ('Train class sizes : {}'.format([x.shape[0] for x in train]))\n",
    "print ('Features          : {}'.format(nfeatures))\n",
    "print ('Iterations        : {}'.format(niter))\n",
    "for iter_idx in range ( niter ):\n",
    "    # Split\n",
    "    (train,test) = round_robin_iteration (iter_idx,f.data_list)\n",
    "    (contig_train_mat, contig_train_vals) = list_to_contig_mat (train, class_vals)\n",
    "    (contig_test_mat, contig_test_vals) = list_to_contig_mat (test, class_vals)\n",
    "\n",
    "    # Normalize\n",
    "    (norm_train, norm_test) = normalize (contig_train_mat, contig_test_mat)\n",
    "    \n",
    "    # Reduce\n",
    "    feature_weights = Pearson(norm_train, contig_train_vals)\n",
    "    (sorted_train, sorted_test) = weigh_sort (norm_train, norm_test, feature_weights)\n",
    "\n",
    "    # Classify\n",
    "    preds,pred_vals = WND5(sorted_train[:,:nfeatures], sorted_test[:,:nfeatures], contig_train_vals)\n",
    "\n",
    "#    preds = rand_forest_clf (sorted_train[:,:nfeatures], sorted_test[:,:nfeatures], contig_train_vals, iter_idx)\n",
    "#    preds = rand_forest_clf (sorted_train[:,:nfeatures], np.asarray([norm_test[1][:,:nfeatures],sorted_test[0][:,:nfeatures]]), contig_train_vals, iter_idx)\n",
    "    for pred_idx in range (len(preds)):\n",
    "        if (preds[pred_idx] == contig_test_vals[pred_idx]):\n",
    "            n_correct[pred_idx] += 1\n",
    "    cumul_acc = [(float(x) / (float(iter_idx)+1.0)) for x in n_correct]\n",
    "    print ('Iteration {}; Predictions: {}; cumulative accuracies: {}'.format(iter_idx, preds, cumul_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    200 features, RFC\n",
    "    Iteration 1119; Predictions: [ 0.  0.]; cumulative accuracies: [0.73125, 0.7294642857142857]\n",
    "    200 features, WND5\n",
    "    Iteration 1119; Predictions: [ 0.  0.]; cumulative accuracies: [0.7366071428571429, 0.7598214285714285]\n",
    "    100 features, WND5\n",
    "    Iteration 1119; Predictions: [ 0.  0.]; cumulative accuracies: [0.75, 0.7205357142857143]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmat = f.ContiguousDataMatrix()\n",
    "print (dmat)\n",
    "print (f.data_list)\n",
    "print (f._contiguous_ground_truth_labels)\n",
    "print (f._contiguous_ground_truth_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iter_idx = 1\n",
    "\n",
    "print dmat\n",
    "dmat2 = np.delete (dmat,[iter_idx],axis=0)\n",
    "print\n",
    "print np.asarray([dmat2[iter_idx]])\n",
    "\n",
    "class_vals = f._contiguous_ground_truth_values\n",
    "print class_vals\n",
    "contig_train_vals = np.delete (class_vals, [iter_idx])\n",
    "contig_test_vals = np.asarray ([class_vals[iter_idx]])\n",
    "print contig_train_vals\n",
    "print contig_test_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class sizes : 39\n",
      "Features          : 100\n",
      "Iterations        : 40\n",
      "Iteration 0; Predictions: 2.3; actual: 1.0\n",
      "Iteration 1; Predictions: 4.33333333333; actual: 6.0\n",
      "Iteration 2; Predictions: 4.93333333333; actual: 1.0\n",
      "Iteration 3; Predictions: 4.8; actual: 1.0\n",
      "Iteration 4; Predictions: 2.76666666667; actual: 4.0\n",
      "Iteration 5; Predictions: 2.53333333333; actual: 7.0\n",
      "Iteration 6; Predictions: 3.46666666667; actual: 1.0\n",
      "Iteration 7; Predictions: 4.23333333333; actual: 2.0\n",
      "Iteration 8; Predictions: 3.6; actual: 5.0\n",
      "Iteration 9; Predictions: 4.53333333333; actual: 4.0\n",
      "Iteration 10; Predictions: 3.46666666667; actual: 2.0\n",
      "Iteration 11; Predictions: 4.93333333333; actual: 2.0\n",
      "Iteration 12; Predictions: 4.56666666667; actual: 3.0\n",
      "Iteration 13; Predictions: 3.43333333333; actual: 5.0\n",
      "Iteration 14; Predictions: 3.1; actual: 4.0\n",
      "Iteration 15; Predictions: 2.96666666667; actual: 2.0\n",
      "Iteration 16; Predictions: 4.06666666667; actual: 2.0\n",
      "Iteration 17; Predictions: 3.2; actual: 5.0\n",
      "Iteration 18; Predictions: 2.16666666667; actual: 4.0\n",
      "Iteration 19; Predictions: 3.3; actual: 2.0\n",
      "Iteration 20; Predictions: 2.93333333333; actual: 4.0\n",
      "Iteration 21; Predictions: 3.13333333333; actual: 6.0\n",
      "Iteration 22; Predictions: 2.96666666667; actual: 1.0\n",
      "Iteration 23; Predictions: 2.43333333333; actual: 2.0\n",
      "Iteration 24; Predictions: 3.66666666667; actual: 3.0\n",
      "Iteration 25; Predictions: 2.43333333333; actual: 5.0\n",
      "Iteration 26; Predictions: 2.43333333333; actual: 3.0\n",
      "Iteration 27; Predictions: 3.4; actual: 2.0\n",
      "Iteration 28; Predictions: 4.73333333333; actual: 6.0\n",
      "Iteration 29; Predictions: 3.13333333333; actual: 3.0\n",
      "Iteration 30; Predictions: 3.3; actual: 3.0\n",
      "Iteration 31; Predictions: 2.9; actual: 8.0\n",
      "Iteration 32; Predictions: 3.96666666667; actual: 7.0\n",
      "Iteration 33; Predictions: 2.1; actual: 6.0\n",
      "Iteration 34; Predictions: 2.46666666667; actual: 3.0\n",
      "Iteration 35; Predictions: 3.26666666667; actual: 3.0\n",
      "Iteration 36; Predictions: 2.7; actual: 2.0\n",
      "Iteration 37; Predictions: 3.53333333333; actual: 5.0\n",
      "Iteration 38; Predictions: 3.66666666667; actual: 1.0\n",
      "Iteration 39; Predictions: 3.13333333333; actual: 2.0\n",
      "R^2: 0.0197249101125, p-value: 0.387377038132\n"
     ]
    }
   ],
   "source": [
    "nfeatures = 100\n",
    "niter = dmat.shape[0]\n",
    "class_vals = f._contiguous_ground_truth_values\n",
    "n_correct = np.asarray( [0]*2)\n",
    "(train,test) = round_robin_iteration (0,f.data_list)\n",
    "print ('Train class sizes : {}'.format(dmat.shape[0]-1))\n",
    "print ('Features          : {}'.format(nfeatures))\n",
    "print ('Iterations        : {}'.format(niter))\n",
    "predictions = []\n",
    "actual = []\n",
    "for iter_idx in range ( niter ):\n",
    "    # Split\n",
    "    contig_train_mat = np.delete(dmat,[iter_idx],axis=0)\n",
    "    contig_test_mat = np.asarray([dmat[iter_idx]])\n",
    "\n",
    "    contig_train_vals = np.delete (class_vals, [iter_idx])\n",
    "    contig_test_vals = np.asarray ([class_vals[iter_idx]])\n",
    "\n",
    "    # Normalize\n",
    "    (norm_train, norm_test) = normalize (contig_train_mat, contig_test_mat)\n",
    "    \n",
    "    # Reduce\n",
    "    feature_weights = Pearson(norm_train, contig_train_vals)\n",
    "    (sorted_train, sorted_test) = weigh_sort (norm_train, norm_test, feature_weights)\n",
    "\n",
    "    # Classify\n",
    "    #preds,pred_val = WND5(sorted_train[:,:nfeatures], sorted_test[:,:nfeatures], contig_train_vals)\n",
    "    pred_val = rand_forest_reg (sorted_train[:,:nfeatures], sorted_test[:,:nfeatures], contig_train_vals, iter_idx)\n",
    "    #pred_val = lin_reg (sorted_train[:,:nfeatures], sorted_test[:,:nfeatures], contig_train_vals)\n",
    "    predictions.append (pred_val[0])\n",
    "    actual.append (class_vals[iter_idx])\n",
    "    print ('Iteration {}; Predictions: {}; actual: {}'.format(iter_idx, predictions[-1], actual[-1]))\n",
    "\n",
    "score, p_value = pearsonr(predictions, actual)\n",
    "score *= score\n",
    "print ('R^2: {}, p-value: {}'.format (score, p_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    200 features RandForReg\n",
    "    R^2: 0.100336411037, p-value: 0.0464318824205\n",
    "    20 features lin reg:\n",
    "    R^2: 0.0491493694884, p-value: 0.169178264743\n",
    "    20 features RandForReg\n",
    "    R^2: 0.0595653398403, p-value: 0.129095037849\n",
    "    100 features RandForReg\n",
    "    R^2: 0.0395069277481, p-value: 0.218869033287\n",
    "    100 features RandForReg - binned, 8 bins.\n",
    "    R^2: 0.0197249101125, p-value: 0.387377038132\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
