{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC7NvG6PJSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f4aaed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.linspace(0, 3*np.pi, 500)\n",
    "plt.plot(x, np.sin(x**2))\n",
    "plt.title('A simple chirp');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=0 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=0 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=0 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=1 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=1 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=1 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=2 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=2 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=2 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=3 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=3 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=3 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=4 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=4 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=4 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=5 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=5 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=5 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=6 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=6 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=6 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=7 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=7 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=7 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=8 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=8 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=8 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=9 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=9 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=9 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=10 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=10 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=10 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=11 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=11 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=11 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=12 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=12 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=12 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=13 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=13 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=13 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=14 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=14 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=14 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=15 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=15 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=15 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=16 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=16 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=16 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=17 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=17 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=17 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=18 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=18 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=18 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=19 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=19 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=19 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=20 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=20 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=20 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=21 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=21 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=21 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=22 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=22 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=22 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=23 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=23 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=23 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=24 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=24 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=24 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=25 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=25 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=25 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=26 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=26 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=26 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"0\" n_features=2919 grp=27 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"0\" n_features=2919 grp=27 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"0\" n_features=2919 grp=27 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"12\" n_features=2919 grp=28 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"12\" n_features=2919 grp=28 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"12\" n_features=2919 grp=28 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"37.1\" n_features=2919 grp=29 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"37.1\" n_features=2919 grp=29 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"37.1\" n_features=2919 grp=29 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"13\" n_features=2919 grp=30 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"13\" n_features=2919 grp=30 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"13\" n_features=2919 grp=30 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"13\" n_features=2919 grp=31 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"13\" n_features=2919 grp=31 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"13\" n_features=2919 grp=31 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"27\" n_features=2919 grp=32 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"27\" n_features=2919 grp=32 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"27\" n_features=2919 grp=32 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"41\" n_features=2919 grp=33 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"41\" n_features=2919 grp=33 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"41\" n_features=2919 grp=33 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"11\" n_features=2919 grp=34 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"11\" n_features=2919 grp=34 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"11\" n_features=2919 grp=34 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"18\" n_features=2919 grp=35 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"18\" n_features=2919 grp=35 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"18\" n_features=2919 grp=35 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"33.4\" n_features=2919 grp=36 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"33.4\" n_features=2919 grp=36 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"33.4\" n_features=2919 grp=36 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"25.5\" n_features=2919 grp=37 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"25.5\" n_features=2919 grp=37 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"25.5\" n_features=2919 grp=37 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"17.8\" n_features=2919 grp=38 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"17.8\" n_features=2919 grp=38 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"17.8\" n_features=2919 grp=38 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"20\" n_features=2919 grp=39 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"20\" n_features=2919 grp=39 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"20\" n_features=2919 grp=39 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"22\" n_features=2919 grp=40 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"22\" n_features=2919 grp=40 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"22\" n_features=2919 grp=40 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"35.6\" n_features=2919 grp=41 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"35.6\" n_features=2919 grp=41 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"35.6\" n_features=2919 grp=41 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"30\" n_features=2919 grp=42 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"30\" n_features=2919 grp=42 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"30\" n_features=2919 grp=42 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"19\" n_features=2919 grp=43 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"19\" n_features=2919 grp=43 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"19\" n_features=2919 grp=43 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"20.1\" n_features=2919 grp=44 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"20.1\" n_features=2919 grp=44 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"20.1\" n_features=2919 grp=44 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"35.1\" n_features=2919 grp=45 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"35.1\" n_features=2919 grp=45 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"35.1\" n_features=2919 grp=45 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"30.2\" n_features=2919 grp=46 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"30.2\" n_features=2919 grp=46 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"30.2\" n_features=2919 grp=46 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"17\" n_features=2919 grp=47 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"17\" n_features=2919 grp=47 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"17\" n_features=2919 grp=47 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"27.1\" n_features=2919 grp=48 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"27.1\" n_features=2919 grp=48 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"27.1\" n_features=2919 grp=48 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"39.7\" n_features=2919 grp=49 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"39.7\" n_features=2919 grp=49 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"39.7\" n_features=2919 grp=49 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"12.2\" n_features=2919 grp=50 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"12.2\" n_features=2919 grp=50 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"12.2\" n_features=2919 grp=50 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"18\" n_features=2919 grp=51 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"18\" n_features=2919 grp=51 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"18\" n_features=2919 grp=51 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"24.3\" n_features=2919 grp=52 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"24.3\" n_features=2919 grp=52 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"24.3\" n_features=2919 grp=52 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"33\" n_features=2919 grp=53 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"33\" n_features=2919 grp=53 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"33\" n_features=2919 grp=53 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"24.2\" n_features=2919 grp=54 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"24.2\" n_features=2919 grp=54 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"24.2\" n_features=2919 grp=54 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"17.7\" n_features=2919 grp=55 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"17.7\" n_features=2919 grp=55 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"17.7\" n_features=2919 grp=55 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"40\" n_features=2919 grp=56 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"40\" n_features=2919 grp=56 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"40\" n_features=2919 grp=56 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"24\" n_features=2919 grp=57 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"24\" n_features=2919 grp=57 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"24\" n_features=2919 grp=57 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"22\" n_features=2919 grp=58 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"22\" n_features=2919 grp=58 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"22\" n_features=2919 grp=58 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"49\" n_features=2919 grp=59 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"49\" n_features=2919 grp=59 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"49\" n_features=2919 grp=59 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"43.7\" n_features=2919 grp=60 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"43.7\" n_features=2919 grp=60 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"43.7\" n_features=2919 grp=60 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"40\" n_features=2919 grp=61 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"40\" n_features=2919 grp=61 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"40\" n_features=2919 grp=61 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"24\" n_features=2919 grp=62 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"24\" n_features=2919 grp=62 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"24\" n_features=2919 grp=62 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"23\" n_features=2919 grp=63 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"23\" n_features=2919 grp=63 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"23\" n_features=2919 grp=63 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"18\" n_features=2919 grp=64 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"18\" n_features=2919 grp=64 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"18\" n_features=2919 grp=64 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"35.6\" n_features=2919 grp=65 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"35.6\" n_features=2919 grp=65 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"35.6\" n_features=2919 grp=65 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"14\" n_features=2919 grp=66 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"14\" n_features=2919 grp=66 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"14\" n_features=2919 grp=66 seq=0 fs_col=2>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice7-l.sig\" label=\"19.3\" n_features=2919 grp=67 seq=0 fs_col=0>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice6-l.sig\" label=\"19.3\" n_features=2919 grp=67 seq=0 fs_col=1>\n",
      "LOADED  <FeatureVector \"T2_map_Resliced_Slice8-l.sig\" label=\"19.3\" n_features=2919 grp=67 seq=0 fs_col=2>\n",
      "NEW FEATURE SPACE FROM FILE LIST: <FeatureSpace \"medial_7_6_8_delta_womac\" n_features=8757 n_total_samples=68 n_samples_per_group=1 n_classes=34 samples_per_class=(\"0\": 28, \"12\": 1, \"37.1\": 1, \"13\": 2, \"27\": 1, \"41\": 1, \"11\": 1, \"18\": 3, \"33.4\": 1, \"25.5\": 1, \"17.8\": 1, \"20\": 1, \"22\": 2, \"35.6\": 2, \"30\": 1, \"19\": 1, \"20.1\": 1, \"35.1\": 1, \"30.2\": 1, \"17\": 1, \"27.1\": 1, \"39.7\": 1, \"12.2\": 1, \"24.3\": 1, \"33\": 1, \"24.2\": 1, \"17.7\": 1, \"40\": 2, \"24\": 2, \"49\": 1, \"43.7\": 1, \"23\": 1, \"14\": 1, \"19.3\": 1)>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from wndcharm.FeatureSpace import FeatureSpace\n",
    "f=FeatureSpace.NewFromFileOfFiles( os.path.expanduser('data/medial_7_6_8_delta_womac.fof'), long=True )\n",
    "f.ToFitFile('data/medial_7_6_8_delta_womac.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.46300000e+03   5.44220000e-02   2.34303000e-01 ...,  -4.20041000e+04\n",
      "    1.33342000e+05   7.16966000e-01]\n",
      " [  2.46100000e+03   3.82510000e-02   4.73540000e-02 ...,  -5.46250000e+04\n",
      "    1.36239000e+05   7.25326000e-01]\n",
      " [  2.46300000e+03   2.86680000e-02   2.27273000e-01 ...,  -3.12424000e+04\n",
      "    1.15157000e+05   7.13205000e-01]\n",
      " ..., \n",
      " [  2.40200000e+03   7.63360000e-02   1.62866000e-01 ...,  -6.03631000e+04\n",
      "    1.30804000e+05   7.21693000e-01]\n",
      " [  2.45000000e+03   1.28302000e-01   7.62710000e-02 ...,  -5.37427000e+04\n",
      "    1.35765000e+05   7.17335000e-01]\n",
      " [  2.43000000e+03   1.49250000e-02   4.86660000e-02 ...,  -4.15241000e+04\n",
      "    1.06458000e+05   7.17794000e-01]]\n",
      "[array([[  2.46300000e+03,   5.44220000e-02,   2.34303000e-01, ...,\n",
      "         -4.20041000e+04,   1.33342000e+05,   7.16966000e-01],\n",
      "       [  2.46100000e+03,   3.82510000e-02,   4.73540000e-02, ...,\n",
      "         -5.46250000e+04,   1.36239000e+05,   7.25326000e-01],\n",
      "       [  2.46300000e+03,   2.86680000e-02,   2.27273000e-01, ...,\n",
      "         -3.12424000e+04,   1.15157000e+05,   7.13205000e-01],\n",
      "       ..., \n",
      "       [  2.46000000e+03,   9.27490000e-02,   1.09422000e-01, ...,\n",
      "         -4.05947000e+04,   1.11102000e+05,   7.22446000e-01],\n",
      "       [  2.46800000e+03,   5.57620000e-02,   4.00000000e-02, ...,\n",
      "         -5.21063000e+04,   1.32438000e+05,   7.16579000e-01],\n",
      "       [  2.46300000e+03,   2.09520000e-02,   1.38211000e-01, ...,\n",
      "         -5.16194000e+04,   1.38129000e+05,   7.18402000e-01]]), array([[  2.47100000e+03,   9.96700000e-03,   9.09090000e-02, ...,\n",
      "         -5.68879000e+04,   1.24726000e+05,   7.11482000e-01]]), array([[  2.46700000e+03,   8.28920000e-02,   4.14750000e-02, ...,\n",
      "         -5.34658000e+04,   1.29016000e+05,   7.17171000e-01]]), array([[  2.30200000e+03,   8.79350000e-02,   1.46444000e-01, ...,\n",
      "         -6.22379000e+04,   1.28003000e+05,   7.28210000e-01],\n",
      "       [  2.46200000e+03,   1.47950000e-01,   2.39520000e-02, ...,\n",
      "         -6.20287000e+04,   1.32556000e+05,   7.22202000e-01]]), array([[  2.43800000e+03,   3.95870000e-02,   9.68800000e-02, ...,\n",
      "         -5.87392000e+04,   1.31402000e+05,   7.15094000e-01]]), array([[  2.46100000e+03,   5.10400000e-02,   5.51820000e-02, ...,\n",
      "         -5.76776000e+04,   1.33002000e+05,   7.27425000e-01]]), array([[  2.09700000e+03,   6.25000000e-02,   8.09060000e-02, ...,\n",
      "         -6.32063000e+04,   1.25624000e+05,   7.26984000e-01]]), array([[  2.45700000e+03,   1.01549000e-01,   9.32480000e-02, ...,\n",
      "         -6.33270000e+04,   1.33923000e+05,   7.24510000e-01],\n",
      "       [  2.42400000e+03,   4.84430000e-02,   7.98120000e-02, ...,\n",
      "         -5.69106000e+04,   1.27462000e+05,   7.18495000e-01],\n",
      "       [  2.45700000e+03,   1.07910000e-02,   5.99680000e-02, ...,\n",
      "         -5.72521000e+04,   1.25122000e+05,   7.15362000e-01]]), array([[  2.46800000e+03,   4.31780000e-02,   6.20270000e-02, ...,\n",
      "         -5.80721000e+04,   1.22935000e+05,   7.16681000e-01]]), array([[  2.41100000e+03,   1.41880000e-01,   6.84900000e-03, ...,\n",
      "         -5.69183000e+04,   1.37633000e+05,   7.31685000e-01]]), array([[  2.42300000e+03,   8.15600000e-02,   1.52910000e-02, ...,\n",
      "         -5.82305000e+04,   1.41897000e+05,   7.19255000e-01]]), array([[  2.44800000e+03,   2.89860000e-02,   9.12050000e-02, ...,\n",
      "         -6.30544000e+04,   1.28148000e+05,   7.22534000e-01]]), array([[  2.45500000e+03,   1.82100000e-03,   9.34150000e-02, ...,\n",
      "         -6.07223000e+04,   1.27807000e+05,   7.18808000e-01],\n",
      "       [  2.36400000e+03,   2.29890000e-02,   1.65109000e-01, ...,\n",
      "         -6.24460000e+04,   1.27172000e+05,   7.16624000e-01]]), array([[  2.42000000e+03,   3.01720000e-02,   2.55878000e-01, ...,\n",
      "         -6.30226000e+04,   1.41483000e+05,   7.17040000e-01],\n",
      "       [  2.43600000e+03,   1.70213000e-01,   1.56250000e-01, ...,\n",
      "         -5.18181000e+04,   1.41752000e+05,   7.12934000e-01]]), array([[  2.40200000e+03,   8.89680000e-02,   9.52400000e-03, ...,\n",
      "         -5.69199000e+04,   1.25305000e+05,   7.08236000e-01]]), array([[  2.38300000e+03,   8.58140000e-02,   1.34230000e-02, ...,\n",
      "         -5.68559000e+04,   1.35509000e+05,   7.16314000e-01]]), array([[  2.44100000e+03,   1.12299000e-01,   1.33226000e-01, ...,\n",
      "         -5.99284000e+04,   1.41273000e+05,   7.18596000e-01]]), array([[  2.46200000e+03,   3.14960000e-02,   5.27700000e-02, ...,\n",
      "         -5.96832000e+04,   1.30087000e+05,   7.22807000e-01]]), array([[  2.46700000e+03,   4.28820000e-02,   2.16495000e-01, ...,\n",
      "         -5.57801000e+04,   1.16417000e+05,   7.13418000e-01]]), array([[  2.40400000e+03,   8.24740000e-02,   1.50769000e-01, ...,\n",
      "         -6.01801000e+04,   1.21447000e+05,   7.20999000e-01]]), array([[  2.44100000e+03,   1.23389000e-01,   1.98083000e-01, ...,\n",
      "         -6.18272000e+04,   1.28877000e+05,   7.33498000e-01]]), array([[  2.39400000e+03,   7.52690000e-02,   1.33676000e-01, ...,\n",
      "         -6.33295000e+04,   1.29084000e+05,   7.18021000e-01]]), array([[  2.45300000e+03,   9.92910000e-02,   1.74089000e-01, ...,\n",
      "         -6.37833000e+04,   1.18731000e+05,   7.15956000e-01]]), array([[  2.47000000e+03,   4.04410000e-02,   1.94904000e-01, ...,\n",
      "         -6.39740000e+04,   1.28504000e+05,   7.26436000e-01]]), array([[  2.42200000e+03,   5.28110000e-02,   6.77970000e-02, ...,\n",
      "         -5.86787000e+04,   1.32068000e+05,   7.29644000e-01]]), array([[  2.17300000e+03,   1.36719000e-01,   1.68450000e-02, ...,\n",
      "         -6.16052000e+04,   1.26405000e+05,   7.24288000e-01]]), array([[  2.43200000e+03,   1.44312000e-01,   7.37460000e-02, ...,\n",
      "         -5.17925000e+04,   1.17332000e+05,   7.18500000e-01]]), array([[  2.43400000e+03,   1.76015000e-01,   3.07801000e-01, ...,\n",
      "         -5.69183000e+04,   1.38707000e+05,   7.24818000e-01],\n",
      "       [  2.32500000e+03,   6.27310000e-02,   1.06220000e-02, ...,\n",
      "         -6.34618000e+04,   1.22814000e+05,   7.18513000e-01]]), array([[  2.23100000e+03,   1.09375000e-01,   1.45427000e-01, ...,\n",
      "         -6.16136000e+04,   1.27906000e+05,   7.27635000e-01],\n",
      "       [  2.46600000e+03,   3.67600000e-03,   5.42640000e-02, ...,\n",
      "         -2.91663000e+04,   1.04807000e+05,   7.11990000e-01]]), array([[  2.45600000e+03,   1.13244000e-01,   2.79150000e-02, ...,\n",
      "         -5.31224000e+04,   1.27364000e+05,   7.16691000e-01]]), array([[  2.46800000e+03,   5.16610000e-02,   1.54971000e-01, ...,\n",
      "         -5.60158000e+04,   1.16523000e+05,   7.13656000e-01]]), array([[  2.40200000e+03,   7.63360000e-02,   1.62866000e-01, ...,\n",
      "         -6.03631000e+04,   1.30804000e+05,   7.21693000e-01]]), array([[  2.45000000e+03,   1.28302000e-01,   7.62710000e-02, ...,\n",
      "         -5.37427000e+04,   1.35765000e+05,   7.17335000e-01]]), array([[  2.43000000e+03,   1.49250000e-02,   4.86660000e-02, ...,\n",
      "         -4.15241000e+04,   1.06458000e+05,   7.17794000e-01]])]\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '12', '37.1', '13', '13', '27', '41', '11', '18', '33.4', '25.5', '17.8', '20', '22', '35.6', '30', '19', '20.1', '35.1', '30.2', '17', '27.1', '39.7', '12.2', '18', '24.3', '33', '24.2', '17.7', '40', '24', '22', '49', '43.7', '40', '24', '23', '18', '35.6', '14', '19.3']\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 37.1, 13.0, 13.0, 27.0, 41.0, 11.0, 18.0, 33.4, 25.5, 17.8, 20.0, 22.0, 35.6, 30.0, 19.0, 20.1, 35.1, 30.2, 17.0, 27.1, 39.7, 12.2, 18.0, 24.3, 33.0, 24.2, 17.7, 40.0, 24.0, 22.0, 49.0, 43.7, 40.0, 24.0, 23.0, 18.0, 35.6, 14.0, 19.3]\n"
     ]
    }
   ],
   "source": [
    "dmat = f.ContiguousDataMatrix()\n",
    "print (dmat)\n",
    "print (f.data_list)\n",
    "print (f._contiguous_ground_truth_labels)\n",
    "print (f._contiguous_ground_truth_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '12', '37.1', '13', '27', '41', '11', '18', '33.4', '25.5', '17.8', '20', '22', '35.6', '30', '19', '20.1', '35.1', '30.2', '17', '27.1', '39.7', '12.2', '24.3', '33', '24.2', '17.7', '40', '24', '49', '43.7', '23', '14', '19.3']\n",
      "[0.0, 12.0, 37.1, 13.0, 27.0, 41.0, 11.0, 18.0, 33.4, 25.5, 17.8, 20.0, 22.0, 35.6, 30.0, 19.0, 20.1, 35.1, 30.2, 17.0, 27.1, 39.7, 12.2, 24.3, 33.0, 24.2, 17.7, 40.0, 24.0, 49.0, 43.7, 23.0, 14.0, 19.3]\n"
     ]
    }
   ],
   "source": [
    "print (f.class_names)\n",
    "class_vals = [float(x) for x in f.class_names]\n",
    "print (class_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.lda import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize (train, test):\n",
    "    norm_train_set = train.copy() \n",
    "    mins, maxs = normalize_by_columns (norm_train_set)\n",
    "    norm_test_set = test.copy() \n",
    "    normalize_by_columns (norm_test_set, mins, maxs)\n",
    "    return (norm_train_set, norm_test_set)\n",
    "\n",
    "def normalize_by_columns ( full_stack, mins = None, maxs = None ):\n",
    "    \"\"\"This is a global function to normalize a matrix by columns.\n",
    "    If numpy 1D arrays of mins and maxs are provided, the matrix will be normalized against these ranges\n",
    "    Otherwise, the mins and maxs will be determined from the matrix, and the matrix will be normalized\n",
    "    against itself. The mins and maxs will be returned as a tuple.\n",
    "    Out of range matrix values will be clipped to min and max (including +/- INF)\n",
    "    zero-range columns will be set to 0.\n",
    "    NANs in the columns will be set to 0.\n",
    "    The normalized output range is hard-coded to 0-100\n",
    "    \"\"\"\n",
    "    # Edge cases to deal with:\n",
    "    # Range determination:\n",
    "    # 1. features that are nan, inf, -inf\n",
    "    # max and min determination must ignore invalid numbers\n",
    "    # nan -> 0, inf -> max, -inf -> min\n",
    "    # Normalization:\n",
    "    # 2. feature values outside of range\n",
    "    # values clipped to range (-inf to min -> min, max to inf -> max) - leaves nan as nan\n",
    "    # 3. feature ranges that are 0 result in nan feature values\n",
    "    # 4. all nan feature values set to 0\n",
    "\n",
    "    # Turn off numpy warnings, since we're taking care of invalid values explicitly\n",
    "    oldsettings = np.seterr(all='ignore')\n",
    "    if (mins is None or maxs is None):\n",
    "        # mask out NANs and +/-INFs to compute min/max\n",
    "        full_stack_m = np.ma.masked_invalid (full_stack, copy=False)\n",
    "        maxs = full_stack_m.max (axis=0)\n",
    "        mins = full_stack_m.min (axis=0)\n",
    "\n",
    "    # clip the values to the min-max range (NANs are left, but +/- INFs are taken care of)\n",
    "    full_stack.clip (mins, maxs, full_stack)\n",
    "    # remake a mask to account for NANs and divide-by-zero from max == min\n",
    "    full_stack_m = np.ma.masked_invalid (full_stack, copy=False)\n",
    "\n",
    "    # Normalize\n",
    "    full_stack_m -= mins\n",
    "    full_stack_m /= (maxs - mins)\n",
    "    # Left over NANs and divide-by-zero from max == min become 0\n",
    "    # Note the deep copy to change the numpy parameter in-place.\n",
    "    full_stack[:] = full_stack_m.filled (0) * 100.0\n",
    "\n",
    "    # return settings to original\n",
    "    np.seterr(**oldsettings)\n",
    "\n",
    "    return (mins,maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stand (train, test):\n",
    "    scaler = StandardScaler()\n",
    "    new_train_set = scaler.fit_transform(train)\n",
    "    new_test_set = scaler.transform(test)\n",
    "    return (new_train_set,new_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def round_robin_iteration (index, data_matrix_list):\n",
    "    '''Does a leave N out, where N is the number of classes.\n",
    "    The class with the smallest number of samples -1 (nsamples - 1) determines training set size.\n",
    "    Picks nsamples-1 for training and testing from a circular list starting at index.\n",
    "    Index ranges from 0 to the product of number of samples in each class.\n",
    "    data_matrix_list is a list of data matrixes, with one matrix per class'''\n",
    "    lengths = [m.shape[0] for m in data_matrix_list]\n",
    "    nclasses = len(lengths)\n",
    "    max_samples = min (lengths) - 1\n",
    "    indexes = [0] * nclasses\n",
    "    cl_index = index\n",
    "    for i in range (nclasses-1,0,-1):\n",
    "        indexes[i] = cl_index / lengths[i]\n",
    "        cl_index -= (indexes[i] * lengths[i])\n",
    "    indexes[0] = cl_index\n",
    "    indexes = list(reversed(indexes))\n",
    "    \n",
    "    train_mats = []\n",
    "    test_mats = []\n",
    "    for class_num in range(nclasses):\n",
    "        class_indexes = [ (count+indexes[class_num]+1) % lengths[class_num] for count in range (max_samples) ]\n",
    "        train_mats.append (np.take (data_matrix_list[class_num], class_indexes, axis=0) )\n",
    "        test_mats.append (np.take (data_matrix_list[class_num], [indexes[class_num]], axis=0) )\n",
    "    return (train_mats, test_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 0 0]\n",
      "  [1 1 1 1 1]\n",
      "  [2 2 2 2 2]\n",
      "  [3 3 3 3 3]\n",
      "  [4 4 4 4 4]\n",
      "  [5 5 5 5 5]\n",
      "  [6 6 6 6 6]\n",
      "  [7 7 7 7 7]]\n",
      "\n",
      " [[0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]]]\n",
      "-------\n",
      "[array([[2, 2, 2, 2, 2]]), array([[0, 1, 2, 3, 4]])]\n",
      "[array([[3, 3, 3, 3, 3],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [5, 5, 5, 5, 5],\n",
      "       [6, 6, 6, 6, 6],\n",
      "       [7, 7, 7, 7, 7],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1]]), array([[0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4]])]\n"
     ]
    }
   ],
   "source": [
    "dat_mat = np.mgrid[0:8,0:5]\n",
    "print (dat_mat)\n",
    "(train,test) = round_robin_iteration (19,dat_mat)\n",
    "print ('-------')\n",
    "print (test)\n",
    "print (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_contig_mat (data_matrix_list, class_vals):\n",
    "    data_mat_contig = np.vstack (data_matrix_list)\n",
    "    class_vals_vec_list = []\n",
    "    for class_idx in range (len(data_matrix_list)):\n",
    "        class_vals_vec_list += [class_vals[class_idx]] * len (data_matrix_list[class_idx])\n",
    "    class_vals_contig = np.asarray(class_vals_vec_list)\n",
    "    return (data_mat_contig,class_vals_contig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Fisher(split):\n",
    "    \"\"\"Takes a FeatureSet_Discrete as input and calculates a Fisher score for\n",
    "    each feature. Returns a newly instantiated instance of FisherFeatureWeights.\n",
    "\n",
    "    For:\n",
    "    N = number of classes\n",
    "    F = number of features\n",
    "    It = total number of images in training set\n",
    "    Ic = number of images in a given class\n",
    "    \"\"\"\n",
    "\n",
    "    if split == None:\n",
    "        import inspect\n",
    "        form_str = 'You passed in a None as a training set to the function {0}.{1}'\t\n",
    "        raise ValueError( form_str.format( cls.__name__, inspect.stack()[1][3] ) )\n",
    "\n",
    "    # we deal with NANs/INFs separately, so turn off numpy warnings about invalid floats.\n",
    "    oldsettings = np.seterr(all='ignore')\n",
    "\n",
    "    def get_train_3d (self):\n",
    "        if self.train_3d is None:\n",
    "            self.train_3d = get_class_mat_list (self.train_set, self.train_classed_labels)\n",
    "        return (self.train_3d)\n",
    "\n",
    "    def get_test_3d (self):\n",
    "        if self.test_3d is None:\n",
    "            self.test_3d = get_class_mat_list (self.test_set, self.test_classed_labels)\n",
    "        return (self.test_3d)\n",
    "\n",
    "    #class_mats = split.get_train_3d()\n",
    "    class_mats = get_class_mat_list (split.train_set, split.train_classed_labels)\n",
    "    # 1D matrix 1 * F\n",
    "    population_means = np.mean( split.train_set, axis = 0 )\n",
    "    n_classes = class_mats.shape[0]\n",
    "    n_features = split.train_set.shape[1]\n",
    "\n",
    "    # 2D matrix shape N * F\n",
    "    intra_class_means = np.empty( [n_classes, n_features] )\n",
    "    # 2D matrix shape N * F\n",
    "    intra_class_variances = np.empty( [n_classes, n_features] )\n",
    "\n",
    "    class_index = 0\n",
    "    for class_feature_matrix in class_mats:\n",
    "        intra_class_means[ class_index ] = np.mean( class_feature_matrix, axis=0 )\n",
    "    # Note that by default, numpy divides by N instead of the more common N-1, hence ddof=1.\n",
    "        intra_class_variances[ class_index ] = np.var( class_feature_matrix, axis=0, ddof=1 )\n",
    "        class_index += 1\n",
    "\n",
    "    # 1D matrix 1 * F\n",
    "    # we deal with NANs/INFs separately, so turn off numpy warnings about invalid floats.\n",
    "    # for the record, in numpy:\n",
    "    # 1./0. = inf, 0./inf = 0., 1./inf = 0. inf/0. = inf, inf/inf = nan\n",
    "    # 0./0. = nan, nan/0. = nan, 0/nan = nan, nan/nan = nan, nan/inf = nan, inf/nan = nan\n",
    "    # We can't deal with NANs only, must also deal with pos/neg infs\n",
    "    # The masked array allows for dealing with \"invalid\" floats, which includes nan and +/-inf\n",
    "    denom = np.mean( intra_class_variances, axis = 0 )\n",
    "    denom[denom == 0] = np.nan\n",
    "    feature_weights_m = np.ma.masked_invalid (\n",
    "            ( np.square( population_means - intra_class_means ).sum( axis = 0 ) /\n",
    "        (n_classes - 1) ) / denom\n",
    "        )\n",
    "    # return numpy error settings to original\n",
    "    np.seterr(**oldsettings)\n",
    "\n",
    "    # the filled(0) method of the masked array sets all nan and infs to 0\n",
    "    fisher_values = feature_weights_m.filled(0).tolist()\n",
    "\n",
    "    return (fisher_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pearson(train_mat, train_vals):\n",
    "    \"\"\"Calculate regression parameters and correlation statistics that fully define\n",
    "    a continuous classifier.\n",
    "\n",
    "    At present the feature weights are proportional the Pearson correlation coefficient\n",
    "    for each given feature.\"\"\"\n",
    "\n",
    "    from scipy import stats\n",
    "\n",
    "    # Known issue: running stats.linregress() with np.seterr (all='raise') has caused\n",
    "    # arithmetic underflow (FloatingPointError: 'underflow encountered in stdtr' )\n",
    "    # I think this is something we can safely ignore in this function, and return settings\n",
    "    # back to normal at the end. -CEC\n",
    "    np.seterr (under='ignore')    \n",
    "\n",
    "    pearson_coeffs = np.zeros(train_mat.shape[1])\n",
    "\n",
    "    for feature_index in range( train_mat.shape[1] ):\n",
    "        slope, intercept, pearson_coeff, p_value, std_err = stats.linregress(\n",
    "            train_vals, train_mat[:,feature_index]\n",
    "        )\n",
    "\n",
    "        pearson_coeffs[feature_index] = pearson_coeff\n",
    "# We're just returning the pearsons^2 now...\n",
    "#    pearson_values = [val*val / r_val_squared_sum for val in pearson_coeffs ]\n",
    "#    pearson_coeffs = (pearson_coeffs * pearson_coeffs) / r_val_squared_sum\n",
    "    pearson_coeffs *= pearson_coeffs\n",
    "    \n",
    "\n",
    "    # Reset numpy\n",
    "    np.seterr (all='raise')\n",
    "\n",
    "    return pearson_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def marg_prob_to_pred_value (marg_probs, class_vals):\n",
    "    weighted = np.array(marg_probs)*np.array(class_vals)\n",
    "    return (np.sum(weighted))\n",
    "\n",
    "def WND5(contig_train_mat, contig_test_mat, contig_train_vals):\n",
    "    n_test_samples = contig_test_mat.shape[0]\n",
    "    n_train_samples = contig_train_mat.shape[0]\n",
    "    predicted_classes = np.zeros(n_test_samples)\n",
    "    predicted_values = np.zeros(n_test_samples)\n",
    "    \n",
    "    epsilon = np.finfo( np.float ).eps\n",
    "    testimg_idx = 0\n",
    "    trainimg_idx = 0\n",
    "    \n",
    "    for testimg_idx in range( n_test_samples ):\n",
    "        # initialize\n",
    "        class_dists = {}\n",
    "        class_counts = {}\n",
    "        classnames_list = []\n",
    "\n",
    "        for trainimg_idx in range( n_train_samples ):\n",
    "            train_class_label = contig_train_vals[trainimg_idx]\n",
    "            if not train_class_label in class_dists:\n",
    "                class_dists [train_class_label] = 0.0\n",
    "                class_counts[train_class_label] = 0.0\n",
    "                classnames_list.append (train_class_label)\n",
    "\n",
    "            dists = np.absolute (contig_train_mat [trainimg_idx] - contig_test_mat [testimg_idx])\n",
    "            w_dist = np.sum( dists )\n",
    "            if w_dist > epsilon:\n",
    "                class_counts[train_class_label] += 1.0\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            w_dist = np.sum( np.square( dists ) )\n",
    "            # The exponent -5 is the \"5\" in \"WND5\"\n",
    "            class_dists[ train_class_label ] += w_dist ** -5\n",
    "\n",
    "        \n",
    "        class_idx = 0\n",
    "        class_similarities = [0]*len(class_dists)\n",
    "        for class_label in classnames_list:\n",
    "            class_similarities[class_idx] = class_dists[class_label] / class_counts[class_label]\n",
    "            class_idx += 1\n",
    "\n",
    "        norm_factor = sum( class_similarities )\n",
    "        marg_probs = np.array( [ x / norm_factor for x in class_similarities ] )\n",
    "\n",
    "        predicted_class_idx = marg_probs.argmax()\n",
    "\n",
    "        predicted_classes[testimg_idx] = classnames_list[ predicted_class_idx ]\n",
    "        predicted_values[testimg_idx] = marg_prob_to_pred_value (marg_probs, classnames_list)\n",
    "\n",
    "    return (predicted_classes, predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_by_weight (the_mat, feature_weights):\n",
    "    i = np.argsort(feature_weights)\n",
    "    sort_mat = the_mat[:,i]\n",
    "    sort_mat = np.fliplr(sort_mat)\n",
    "    return (sort_mat)\n",
    "\n",
    "def weigh_sort(train, test, feature_weights):\n",
    "    weigh_train = np.multiply (norm_train, feature_weights)\n",
    "    weigh_test = np.multiply (norm_test, feature_weights)\n",
    "\n",
    "    sorted_train = sort_by_weight (weigh_train, feature_weights)\n",
    "    sorted_test = sort_by_weight (weigh_test, feature_weights)\n",
    "    return (sorted_train, sorted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand_forest_clf (contig_train_mat, contig_test_mat, contig_train_vals, rnd_state = None):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators = 30, random_state = rnd_state)\n",
    "    clf.fit(contig_train_mat, contig_train_vals)\n",
    "    predicted_classes = clf.predict(contig_test_mat)\n",
    "    return (predicted_classes)\n",
    "def rand_forest_reg (contig_train_mat, contig_test_mat, contig_train_vals, rnd_state = None):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    forest = RandomForestRegressor(n_estimators=30, random_state = rnd_state)\n",
    "    forest.fit(contig_train_mat, contig_train_vals)\n",
    "    predicted = forest.predict(contig_test_mat)\n",
    "    return (predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(contig_train_mat, contig_test_mat, contig_train_vals):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(contig_train_mat, contig_train_vals)\n",
    "    predicted = lin_reg.predict(contig_test_mat)\n",
    "    return (predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.46300000e+03   5.44220000e-02   2.34303000e-01 ...,  -4.20041000e+04\n",
      "    1.33342000e+05   7.16966000e-01]\n",
      " [  2.46100000e+03   3.82510000e-02   4.73540000e-02 ...,  -5.46250000e+04\n",
      "    1.36239000e+05   7.25326000e-01]\n",
      " [  2.46300000e+03   2.86680000e-02   2.27273000e-01 ...,  -3.12424000e+04\n",
      "    1.15157000e+05   7.13205000e-01]\n",
      " ..., \n",
      " [  2.40200000e+03   7.63360000e-02   1.62866000e-01 ...,  -6.03631000e+04\n",
      "    1.30804000e+05   7.21693000e-01]\n",
      " [  2.45000000e+03   1.28302000e-01   7.62710000e-02 ...,  -5.37427000e+04\n",
      "    1.35765000e+05   7.17335000e-01]\n",
      " [  2.43000000e+03   1.49250000e-02   4.86660000e-02 ...,  -4.15241000e+04\n",
      "    1.06458000e+05   7.17794000e-01]]\n",
      "[array([[  2.46300000e+03,   5.44220000e-02,   2.34303000e-01, ...,\n",
      "         -4.20041000e+04,   1.33342000e+05,   7.16966000e-01],\n",
      "       [  2.46100000e+03,   3.82510000e-02,   4.73540000e-02, ...,\n",
      "         -5.46250000e+04,   1.36239000e+05,   7.25326000e-01],\n",
      "       [  2.46300000e+03,   2.86680000e-02,   2.27273000e-01, ...,\n",
      "         -3.12424000e+04,   1.15157000e+05,   7.13205000e-01],\n",
      "       ..., \n",
      "       [  2.46000000e+03,   9.27490000e-02,   1.09422000e-01, ...,\n",
      "         -4.05947000e+04,   1.11102000e+05,   7.22446000e-01],\n",
      "       [  2.46800000e+03,   5.57620000e-02,   4.00000000e-02, ...,\n",
      "         -5.21063000e+04,   1.32438000e+05,   7.16579000e-01],\n",
      "       [  2.46300000e+03,   2.09520000e-02,   1.38211000e-01, ...,\n",
      "         -5.16194000e+04,   1.38129000e+05,   7.18402000e-01]]), array([[  2.47100000e+03,   9.96700000e-03,   9.09090000e-02, ...,\n",
      "         -5.68879000e+04,   1.24726000e+05,   7.11482000e-01]]), array([[  2.46700000e+03,   8.28920000e-02,   4.14750000e-02, ...,\n",
      "         -5.34658000e+04,   1.29016000e+05,   7.17171000e-01]]), array([[  2.30200000e+03,   8.79350000e-02,   1.46444000e-01, ...,\n",
      "         -6.22379000e+04,   1.28003000e+05,   7.28210000e-01],\n",
      "       [  2.46200000e+03,   1.47950000e-01,   2.39520000e-02, ...,\n",
      "         -6.20287000e+04,   1.32556000e+05,   7.22202000e-01]]), array([[  2.43800000e+03,   3.95870000e-02,   9.68800000e-02, ...,\n",
      "         -5.87392000e+04,   1.31402000e+05,   7.15094000e-01]]), array([[  2.46100000e+03,   5.10400000e-02,   5.51820000e-02, ...,\n",
      "         -5.76776000e+04,   1.33002000e+05,   7.27425000e-01]]), array([[  2.09700000e+03,   6.25000000e-02,   8.09060000e-02, ...,\n",
      "         -6.32063000e+04,   1.25624000e+05,   7.26984000e-01]]), array([[  2.45700000e+03,   1.01549000e-01,   9.32480000e-02, ...,\n",
      "         -6.33270000e+04,   1.33923000e+05,   7.24510000e-01],\n",
      "       [  2.42400000e+03,   4.84430000e-02,   7.98120000e-02, ...,\n",
      "         -5.69106000e+04,   1.27462000e+05,   7.18495000e-01],\n",
      "       [  2.45700000e+03,   1.07910000e-02,   5.99680000e-02, ...,\n",
      "         -5.72521000e+04,   1.25122000e+05,   7.15362000e-01]]), array([[  2.46800000e+03,   4.31780000e-02,   6.20270000e-02, ...,\n",
      "         -5.80721000e+04,   1.22935000e+05,   7.16681000e-01]]), array([[  2.41100000e+03,   1.41880000e-01,   6.84900000e-03, ...,\n",
      "         -5.69183000e+04,   1.37633000e+05,   7.31685000e-01]]), array([[  2.42300000e+03,   8.15600000e-02,   1.52910000e-02, ...,\n",
      "         -5.82305000e+04,   1.41897000e+05,   7.19255000e-01]]), array([[  2.44800000e+03,   2.89860000e-02,   9.12050000e-02, ...,\n",
      "         -6.30544000e+04,   1.28148000e+05,   7.22534000e-01]]), array([[  2.45500000e+03,   1.82100000e-03,   9.34150000e-02, ...,\n",
      "         -6.07223000e+04,   1.27807000e+05,   7.18808000e-01],\n",
      "       [  2.36400000e+03,   2.29890000e-02,   1.65109000e-01, ...,\n",
      "         -6.24460000e+04,   1.27172000e+05,   7.16624000e-01]]), array([[  2.42000000e+03,   3.01720000e-02,   2.55878000e-01, ...,\n",
      "         -6.30226000e+04,   1.41483000e+05,   7.17040000e-01],\n",
      "       [  2.43600000e+03,   1.70213000e-01,   1.56250000e-01, ...,\n",
      "         -5.18181000e+04,   1.41752000e+05,   7.12934000e-01]]), array([[  2.40200000e+03,   8.89680000e-02,   9.52400000e-03, ...,\n",
      "         -5.69199000e+04,   1.25305000e+05,   7.08236000e-01]]), array([[  2.38300000e+03,   8.58140000e-02,   1.34230000e-02, ...,\n",
      "         -5.68559000e+04,   1.35509000e+05,   7.16314000e-01]]), array([[  2.44100000e+03,   1.12299000e-01,   1.33226000e-01, ...,\n",
      "         -5.99284000e+04,   1.41273000e+05,   7.18596000e-01]]), array([[  2.46200000e+03,   3.14960000e-02,   5.27700000e-02, ...,\n",
      "         -5.96832000e+04,   1.30087000e+05,   7.22807000e-01]]), array([[  2.46700000e+03,   4.28820000e-02,   2.16495000e-01, ...,\n",
      "         -5.57801000e+04,   1.16417000e+05,   7.13418000e-01]]), array([[  2.40400000e+03,   8.24740000e-02,   1.50769000e-01, ...,\n",
      "         -6.01801000e+04,   1.21447000e+05,   7.20999000e-01]]), array([[  2.44100000e+03,   1.23389000e-01,   1.98083000e-01, ...,\n",
      "         -6.18272000e+04,   1.28877000e+05,   7.33498000e-01]]), array([[  2.39400000e+03,   7.52690000e-02,   1.33676000e-01, ...,\n",
      "         -6.33295000e+04,   1.29084000e+05,   7.18021000e-01]]), array([[  2.45300000e+03,   9.92910000e-02,   1.74089000e-01, ...,\n",
      "         -6.37833000e+04,   1.18731000e+05,   7.15956000e-01]]), array([[  2.47000000e+03,   4.04410000e-02,   1.94904000e-01, ...,\n",
      "         -6.39740000e+04,   1.28504000e+05,   7.26436000e-01]]), array([[  2.42200000e+03,   5.28110000e-02,   6.77970000e-02, ...,\n",
      "         -5.86787000e+04,   1.32068000e+05,   7.29644000e-01]]), array([[  2.17300000e+03,   1.36719000e-01,   1.68450000e-02, ...,\n",
      "         -6.16052000e+04,   1.26405000e+05,   7.24288000e-01]]), array([[  2.43200000e+03,   1.44312000e-01,   7.37460000e-02, ...,\n",
      "         -5.17925000e+04,   1.17332000e+05,   7.18500000e-01]]), array([[  2.43400000e+03,   1.76015000e-01,   3.07801000e-01, ...,\n",
      "         -5.69183000e+04,   1.38707000e+05,   7.24818000e-01],\n",
      "       [  2.32500000e+03,   6.27310000e-02,   1.06220000e-02, ...,\n",
      "         -6.34618000e+04,   1.22814000e+05,   7.18513000e-01]]), array([[  2.23100000e+03,   1.09375000e-01,   1.45427000e-01, ...,\n",
      "         -6.16136000e+04,   1.27906000e+05,   7.27635000e-01],\n",
      "       [  2.46600000e+03,   3.67600000e-03,   5.42640000e-02, ...,\n",
      "         -2.91663000e+04,   1.04807000e+05,   7.11990000e-01]]), array([[  2.45600000e+03,   1.13244000e-01,   2.79150000e-02, ...,\n",
      "         -5.31224000e+04,   1.27364000e+05,   7.16691000e-01]]), array([[  2.46800000e+03,   5.16610000e-02,   1.54971000e-01, ...,\n",
      "         -5.60158000e+04,   1.16523000e+05,   7.13656000e-01]]), array([[  2.40200000e+03,   7.63360000e-02,   1.62866000e-01, ...,\n",
      "         -6.03631000e+04,   1.30804000e+05,   7.21693000e-01]]), array([[  2.45000000e+03,   1.28302000e-01,   7.62710000e-02, ...,\n",
      "         -5.37427000e+04,   1.35765000e+05,   7.17335000e-01]]), array([[  2.43000000e+03,   1.49250000e-02,   4.86660000e-02, ...,\n",
      "         -4.15241000e+04,   1.06458000e+05,   7.17794000e-01]])]\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '12', '37.1', '13', '13', '27', '41', '11', '18', '33.4', '25.5', '17.8', '20', '22', '35.6', '30', '19', '20.1', '35.1', '30.2', '17', '27.1', '39.7', '12.2', '18', '24.3', '33', '24.2', '17.7', '40', '24', '22', '49', '43.7', '40', '24', '23', '18', '35.6', '14', '19.3']\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 37.1, 13.0, 13.0, 27.0, 41.0, 11.0, 18.0, 33.4, 25.5, 17.8, 20.0, 22.0, 35.6, 30.0, 19.0, 20.1, 35.1, 30.2, 17.0, 27.1, 39.7, 12.2, 18.0, 24.3, 33.0, 24.2, 17.7, 40.0, 24.0, 22.0, 49.0, 43.7, 40.0, 24.0, 23.0, 18.0, 35.6, 14.0, 19.3]\n"
     ]
    }
   ],
   "source": [
    "dmat = f.ContiguousDataMatrix()\n",
    "print (dmat)\n",
    "print (f.data_list)\n",
    "print (f._contiguous_ground_truth_labels)\n",
    "print (f._contiguous_ground_truth_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.46300000e+03   5.44220000e-02   2.34303000e-01 ...,  -4.20041000e+04\n",
      "    1.33342000e+05   7.16966000e-01]\n",
      " [  2.46100000e+03   3.82510000e-02   4.73540000e-02 ...,  -5.46250000e+04\n",
      "    1.36239000e+05   7.25326000e-01]\n",
      " [  2.46300000e+03   2.86680000e-02   2.27273000e-01 ...,  -3.12424000e+04\n",
      "    1.15157000e+05   7.13205000e-01]\n",
      " ..., \n",
      " [  2.40200000e+03   7.63360000e-02   1.62866000e-01 ...,  -6.03631000e+04\n",
      "    1.30804000e+05   7.21693000e-01]\n",
      " [  2.45000000e+03   1.28302000e-01   7.62710000e-02 ...,  -5.37427000e+04\n",
      "    1.35765000e+05   7.17335000e-01]\n",
      " [  2.43000000e+03   1.49250000e-02   4.86660000e-02 ...,  -4.15241000e+04\n",
      "    1.06458000e+05   7.17794000e-01]]\n",
      "\n",
      "[[  2.46300000e+03   2.86680000e-02   2.27273000e-01 ...,  -3.12424000e+04\n",
      "    1.15157000e+05   7.13205000e-01]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 37.1, 13.0, 13.0, 27.0, 41.0, 11.0, 18.0, 33.4, 25.5, 17.8, 20.0, 22.0, 35.6, 30.0, 19.0, 20.1, 35.1, 30.2, 17.0, 27.1, 39.7, 12.2, 18.0, 24.3, 33.0, 24.2, 17.7, 40.0, 24.0, 22.0, 49.0, 43.7, 40.0, 24.0, 23.0, 18.0, 35.6, 14.0, 19.3]\n",
      "[  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.   12.   37.1  13.   13.   27.   41.   11.   18.   33.4\n",
      "  25.5  17.8  20.   22.   35.6  30.   19.   20.1  35.1  30.2  17.   27.1\n",
      "  39.7  12.2  18.   24.3  33.   24.2  17.7  40.   24.   22.   49.   43.7\n",
      "  40.   24.   23.   18.   35.6  14.   19.3]\n",
      "[ 0.]\n"
     ]
    }
   ],
   "source": [
    "iter_idx = 1\n",
    "\n",
    "print dmat\n",
    "dmat2 = np.delete (dmat,[iter_idx],axis=0)\n",
    "print\n",
    "print np.asarray([dmat2[iter_idx]])\n",
    "\n",
    "class_vals = f._contiguous_ground_truth_values\n",
    "print class_vals\n",
    "contig_train_vals = np.delete (class_vals, [iter_idx])\n",
    "contig_test_vals = np.asarray ([class_vals[iter_idx]])\n",
    "print contig_train_vals\n",
    "print contig_test_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class sizes : 67\n",
      "Features          : 1000\n",
      "Iterations        : 68\n",
      "Iteration 0; Predictions: 8.07309220527; actual: 0.0\n",
      "Iteration 1; Predictions: 15.6846715703; actual: 0.0\n",
      "Iteration 2; Predictions: 10.6642170704; actual: 0.0\n",
      "Iteration 3; Predictions: 14.6765331801; actual: 0.0\n",
      "Iteration 4; Predictions: 12.7261757653; actual: 0.0\n",
      "Iteration 5; Predictions: 12.7261757653; actual: 0.0\n",
      "Iteration 6; Predictions: 18.7983357259; actual: 0.0\n",
      "Iteration 7; Predictions: 25.45248113; actual: 0.0\n",
      "Iteration 8; Predictions: 13.8133721843; actual: 0.0\n",
      "Iteration 9; Predictions: 21.8712429271; actual: 0.0\n",
      "Iteration 10; Predictions: 20.153050893; actual: 0.0\n",
      "Iteration 11; Predictions: 21.9328778106; actual: 0.0\n",
      "Iteration 12; Predictions: 17.2827691602; actual: 0.0\n",
      "Iteration 13; Predictions: 14.6666248737; actual: 0.0\n",
      "Iteration 14; Predictions: 27.7825700637; actual: 0.0\n",
      "Iteration 15; Predictions: 27.7231619987; actual: 0.0\n",
      "Iteration 16; Predictions: 19.4462152914; actual: 0.0\n",
      "Iteration 17; Predictions: 22.4474999542; actual: 0.0\n",
      "Iteration 18; Predictions: 21.8173144213; actual: 0.0\n",
      "Iteration 19; Predictions: 31.9945241023; actual: 0.0\n",
      "Iteration 20; Predictions: 17.0144110145; actual: 0.0\n",
      "Iteration 21; Predictions: 23.3808721756; actual: 0.0\n",
      "Iteration 22; Predictions: 20.6562178789; actual: 0.0\n",
      "Iteration 23; Predictions: 17.768489224; actual: 0.0\n",
      "Iteration 24; Predictions: 11.7785666326; actual: 0.0\n",
      "Iteration 25; Predictions: 19.6223816416; actual: 0.0\n",
      "Iteration 26; Predictions: 33.1541632385; actual: 0.0\n",
      "Iteration 27; Predictions: 19.2870387638; actual: 0.0\n",
      "Iteration 28; Predictions: 23.8994402634; actual: 12.0\n",
      "Iteration 29; Predictions: 20.0080673889; actual: 37.1\n",
      "Iteration 30; Predictions: 39.7994479223; actual: 13.0\n",
      "Iteration 31; Predictions: 27.5534446412; actual: 13.0\n",
      "Iteration 32; Predictions: 25.5871102621; actual: 27.0\n",
      "Iteration 33; Predictions: 14.1396556747; actual: 41.0\n",
      "Iteration 34; Predictions: 29.6190226061; actual: 11.0\n",
      "Iteration 35; Predictions: 19.0783876339; actual: 18.0\n",
      "Iteration 36; Predictions: 32.7629561138; actual: 33.4\n",
      "Iteration 37; Predictions: 21.7286375165; actual: 25.5\n",
      "Iteration 38; Predictions: 16.6793282677; actual: 17.8\n",
      "Iteration 39; Predictions: 25.3991074243; actual: 20.0\n",
      "Iteration 40; Predictions: 22.4112190609; actual: 22.0\n",
      "Iteration 41; Predictions: 26.1286706172; actual: 35.6\n",
      "Iteration 42; Predictions: 23.0821144983; actual: 30.0\n",
      "Iteration 43; Predictions: 29.8791244281; actual: 19.0\n",
      "Iteration 44; Predictions: 19.5968841036; actual: 20.1\n",
      "Iteration 45; Predictions: 24.0542368657; actual: 35.1\n",
      "Iteration 46; Predictions: 15.7018704395; actual: 30.2\n",
      "Iteration 47; Predictions: 24.4633481818; actual: 17.0\n",
      "Iteration 48; Predictions: 24.2560338934; actual: 27.1\n",
      "Iteration 49; Predictions: 16.4760486463; actual: 39.7\n",
      "Iteration 50; Predictions: 18.0194929185; actual: 12.2\n",
      "Iteration 51; Predictions: 25.273864821; actual: 18.0\n",
      "Iteration 52; Predictions: 27.4068423129; actual: 24.3\n",
      "Iteration 53; Predictions: 24.4468711528; actual: 33.0\n",
      "Iteration 54; Predictions: 24.7389052277; actual: 24.2\n",
      "Iteration 55; Predictions: 28.0615938424; actual: 17.7\n",
      "Iteration 56; Predictions: 23.6070385874; actual: 40.0\n",
      "Iteration 57; Predictions: 12.4298427358; actual: 24.0\n",
      "Iteration 58; Predictions: 28.1988191344; actual: 22.0\n",
      "Iteration 59; Predictions: 26.9940049903; actual: 49.0\n",
      "Iteration 60; Predictions: 29.6496575366; actual: 43.7\n",
      "Iteration 61; Predictions: 13.0049635356; actual: 40.0\n",
      "Iteration 62; Predictions: 1.71367354242; actual: 24.0\n",
      "Iteration 63; Predictions: 19.2807182338; actual: 23.0\n",
      "Iteration 64; Predictions: 12.2279054134; actual: 18.0\n",
      "Iteration 65; Predictions: 22.6658068315; actual: 35.6\n",
      "Iteration 66; Predictions: 27.2186253608; actual: 14.0\n",
      "Iteration 67; Predictions: 19.7216226236; actual: 19.3\n",
      "R^2: 0.025621122081, p-value: 0.192270457138\n"
     ]
    }
   ],
   "source": [
    "nfeatures = 1000\n",
    "niter = dmat.shape[0]\n",
    "class_vals = f._contiguous_ground_truth_values\n",
    "n_correct = np.asarray( [0]*2)\n",
    "(train,test) = round_robin_iteration (0,f.data_list)\n",
    "print ('Train class sizes : {}'.format(dmat.shape[0]-1))\n",
    "print ('Features          : {}'.format(nfeatures))\n",
    "print ('Iterations        : {}'.format(niter))\n",
    "predictions = []\n",
    "actual = []\n",
    "for iter_idx in range ( niter ):\n",
    "    # Split\n",
    "    contig_train_mat = np.delete(dmat,[iter_idx],axis=0)\n",
    "    contig_test_mat = np.asarray([dmat[iter_idx]])\n",
    "\n",
    "    contig_train_vals = np.delete (class_vals, [iter_idx])\n",
    "    contig_test_vals = np.asarray ([class_vals[iter_idx]])\n",
    "\n",
    "    # Normalize\n",
    "    (norm_train, norm_test) = normalize (contig_train_mat, contig_test_mat)\n",
    "    \n",
    "    # Reduce\n",
    "    feature_weights = Pearson(norm_train, contig_train_vals)\n",
    "    (sorted_train, sorted_test) = weigh_sort (norm_train, norm_test, feature_weights)\n",
    "\n",
    "    # Classify\n",
    "    preds,pred_val = WND5(sorted_train[:,:nfeatures], sorted_test[:,:nfeatures], contig_train_vals)\n",
    "    #pred_val = rand_forest_reg (sorted_train[:,:nfeatures], sorted_test[:,:nfeatures], contig_train_vals, iter_idx)\n",
    "    #pred_val = lin_reg (sorted_train[:,:nfeatures], sorted_test[:,:nfeatures], contig_train_vals)\n",
    "    predictions.append (pred_val[0])\n",
    "    actual.append (class_vals[iter_idx])\n",
    "    print ('Iteration {}; Predictions: {}; actual: {}'.format(iter_idx, predictions[-1], actual[-1]))\n",
    "\n",
    "score, p_value = pearsonr(predictions, actual)\n",
    "score *= score\n",
    "print ('R^2: {}, p-value: {}'.format (score, p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wnd5\n",
    "Train class sizes : 67\n",
    "Features          : 1000\n",
    "Iterations        : 68\n",
    "Iteration 0; Predictions: 8.07309220527; actual: 0.0\n",
    "Iteration 1; Predictions: 15.6846715703; actual: 0.0\n",
    "Iteration 2; Predictions: 10.6642170704; actual: 0.0\n",
    "Iteration 3; Predictions: 14.6765331801; actual: 0.0\n",
    "Iteration 4; Predictions: 12.7261757653; actual: 0.0\n",
    "Iteration 5; Predictions: 12.7261757653; actual: 0.0\n",
    "Iteration 6; Predictions: 18.7983357259; actual: 0.0\n",
    "Iteration 7; Predictions: 25.45248113; actual: 0.0\n",
    "Iteration 8; Predictions: 13.8133721843; actual: 0.0\n",
    "Iteration 9; Predictions: 21.8712429271; actual: 0.0\n",
    "Iteration 10; Predictions: 20.153050893; actual: 0.0\n",
    "Iteration 11; Predictions: 21.9328778106; actual: 0.0\n",
    "Iteration 12; Predictions: 17.2827691602; actual: 0.0\n",
    "Iteration 13; Predictions: 14.6666248737; actual: 0.0\n",
    "Iteration 14; Predictions: 27.7825700637; actual: 0.0\n",
    "Iteration 15; Predictions: 27.7231619987; actual: 0.0\n",
    "Iteration 16; Predictions: 19.4462152914; actual: 0.0\n",
    "Iteration 17; Predictions: 22.4474999542; actual: 0.0\n",
    "Iteration 18; Predictions: 21.8173144213; actual: 0.0\n",
    "Iteration 19; Predictions: 31.9945241023; actual: 0.0\n",
    "Iteration 20; Predictions: 17.0144110145; actual: 0.0\n",
    "Iteration 21; Predictions: 23.3808721756; actual: 0.0\n",
    "Iteration 22; Predictions: 20.6562178789; actual: 0.0\n",
    "Iteration 23; Predictions: 17.768489224; actual: 0.0\n",
    "Iteration 24; Predictions: 11.7785666326; actual: 0.0\n",
    "Iteration 25; Predictions: 19.6223816416; actual: 0.0\n",
    "Iteration 26; Predictions: 33.1541632385; actual: 0.0\n",
    "Iteration 27; Predictions: 19.2870387638; actual: 0.0\n",
    "Iteration 28; Predictions: 23.8994402634; actual: 12.0\n",
    "Iteration 29; Predictions: 20.0080673889; actual: 37.1\n",
    "Iteration 30; Predictions: 39.7994479223; actual: 13.0\n",
    "Iteration 31; Predictions: 27.5534446412; actual: 13.0\n",
    "Iteration 32; Predictions: 25.5871102621; actual: 27.0\n",
    "Iteration 33; Predictions: 14.1396556747; actual: 41.0\n",
    "Iteration 34; Predictions: 29.6190226061; actual: 11.0\n",
    "Iteration 35; Predictions: 19.0783876339; actual: 18.0\n",
    "Iteration 36; Predictions: 32.7629561138; actual: 33.4\n",
    "Iteration 37; Predictions: 21.7286375165; actual: 25.5\n",
    "Iteration 38; Predictions: 16.6793282677; actual: 17.8\n",
    "Iteration 39; Predictions: 25.3991074243; actual: 20.0\n",
    "Iteration 40; Predictions: 22.4112190609; actual: 22.0\n",
    "Iteration 41; Predictions: 26.1286706172; actual: 35.6\n",
    "Iteration 42; Predictions: 23.0821144983; actual: 30.0\n",
    "Iteration 43; Predictions: 29.8791244281; actual: 19.0\n",
    "Iteration 44; Predictions: 19.5968841036; actual: 20.1\n",
    "Iteration 45; Predictions: 24.0542368657; actual: 35.1\n",
    "Iteration 46; Predictions: 15.7018704395; actual: 30.2\n",
    "Iteration 47; Predictions: 24.4633481818; actual: 17.0\n",
    "Iteration 48; Predictions: 24.2560338934; actual: 27.1\n",
    "Iteration 49; Predictions: 16.4760486463; actual: 39.7\n",
    "Iteration 50; Predictions: 18.0194929185; actual: 12.2\n",
    "Iteration 51; Predictions: 25.273864821; actual: 18.0\n",
    "Iteration 52; Predictions: 27.4068423129; actual: 24.3\n",
    "Iteration 53; Predictions: 24.4468711528; actual: 33.0\n",
    "Iteration 54; Predictions: 24.7389052277; actual: 24.2\n",
    "Iteration 55; Predictions: 28.0615938424; actual: 17.7\n",
    "Iteration 56; Predictions: 23.6070385874; actual: 40.0\n",
    "Iteration 57; Predictions: 12.4298427358; actual: 24.0\n",
    "Iteration 58; Predictions: 28.1988191344; actual: 22.0\n",
    "Iteration 59; Predictions: 26.9940049903; actual: 49.0\n",
    "Iteration 60; Predictions: 29.6496575366; actual: 43.7\n",
    "Iteration 61; Predictions: 13.0049635356; actual: 40.0\n",
    "Iteration 62; Predictions: 1.71367354242; actual: 24.0\n",
    "Iteration 63; Predictions: 19.2807182338; actual: 23.0\n",
    "Iteration 64; Predictions: 12.2279054134; actual: 18.0\n",
    "Iteration 65; Predictions: 22.6658068315; actual: 35.6\n",
    "Iteration 66; Predictions: 27.2186253608; actual: 14.0\n",
    "Iteration 67; Predictions: 19.7216226236; actual: 19.3\n",
    "R^2: 0.025621122081, p-value: 0.192270457138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Train class sizes : 67\n",
    "Features          : 15\n",
    "Iterations        : 68\n",
    "Iteration 0; Predictions: -0.363704071417; actual: 0.0\n",
    "Iteration 1; Predictions: 0.838834422119; actual: 0.0\n",
    "Iteration 2; Predictions: 0.367916519606; actual: 0.0\n",
    "Iteration 3; Predictions: 0.61592784943; actual: 0.0\n",
    "Iteration 4; Predictions: -0.430848982547; actual: 0.0\n",
    "Iteration 5; Predictions: -0.430848982547; actual: 0.0\n",
    "Iteration 6; Predictions: 1.68136863238; actual: 0.0\n",
    "Iteration 7; Predictions: 2.14574839416; actual: 0.0\n",
    "Iteration 8; Predictions: -0.142104278572; actual: 0.0\n",
    "Iteration 9; Predictions: 0.230966513484; actual: 0.0\n",
    "Iteration 10; Predictions: 0.547289049598; actual: 0.0\n",
    "Iteration 11; Predictions: 0.684491735839; actual: 0.0\n",
    "Iteration 12; Predictions: 0.361664007205; actual: 0.0\n",
    "Iteration 13; Predictions: 0.831611158148; actual: 0.0\n",
    "Iteration 14; Predictions: 1.48638585041; actual: 0.0\n",
    "Iteration 15; Predictions: 0.768037065858; actual: 0.0\n",
    "Iteration 16; Predictions: 0.817013923817; actual: 0.0\n",
    "Iteration 17; Predictions: -0.197170243909; actual: 0.0\n",
    "Iteration 18; Predictions: 1.02341999213; actual: 0.0\n",
    "Iteration 19; Predictions: 1.11762401743; actual: 0.0\n",
    "Iteration 20; Predictions: 0.418547203436; actual: 0.0\n",
    "Iteration 21; Predictions: 2.06663645028; actual: 0.0\n",
    "Iteration 22; Predictions: 0.228880388558; actual: 0.0\n",
    "Iteration 23; Predictions: -0.0540666915222; actual: 0.0\n",
    "Iteration 24; Predictions: 0.570354418943; actual: 0.0\n",
    "Iteration 25; Predictions: -0.327619722271; actual: 0.0\n",
    "Iteration 26; Predictions: 1.09593800836; actual: 0.0\n",
    "Iteration 27; Predictions: 1.11879371121; actual: 0.0\n",
    "Iteration 28; Predictions: 1.15762768975; actual: 1.0\n",
    "Iteration 29; Predictions: 0.910703528097; actual: 3.0\n",
    "Iteration 30; Predictions: 2.57552511708; actual: 1.0\n",
    "Iteration 31; Predictions: 0.624512428449; actual: 1.0\n",
    "Iteration 32; Predictions: 2.20137656481; actual: 2.0\n",
    "Iteration 33; Predictions: 1.8472546494; actual: 4.0\n",
    "Iteration 34; Predictions: 2.69721559274; actual: 1.0\n",
    "Iteration 35; Predictions: 1.01355173463; actual: 1.0\n",
    "Iteration 36; Predictions: 2.81930388956; actual: 3.0\n",
    "Iteration 37; Predictions: 1.64175937408; actual: 2.0\n",
    "Iteration 38; Predictions: 0.512714479804; actual: 1.0\n",
    "Iteration 39; Predictions: 3.1655911926; actual: 1.0\n",
    "Iteration 40; Predictions: 2.56228342201; actual: 2.0\n",
    "Iteration 41; Predictions: 1.83304057407; actual: 3.0\n",
    "Iteration 42; Predictions: 1.45903313021; actual: 2.0\n",
    "Iteration 43; Predictions: 1.79888182656; actual: 1.0\n",
    "Iteration 44; Predictions: 0.706905312341; actual: 2.0\n",
    "Iteration 45; Predictions: 1.94805174047; actual: 3.0\n",
    "Iteration 46; Predictions: 1.64764979236; actual: 2.0\n",
    "Iteration 47; Predictions: 2.11660885658; actual: 1.0\n",
    "Iteration 48; Predictions: 2.79759115696; actual: 2.0\n",
    "Iteration 49; Predictions: 1.05020455457; actual: 3.0\n",
    "Iteration 50; Predictions: 0.498414033393; actual: 1.0\n",
    "Iteration 51; Predictions: -0.565670999993; actual: 1.0\n",
    "Iteration 52; Predictions: 1.30635332937; actual: 2.0\n",
    "Iteration 53; Predictions: 2.08781121177; actual: 3.0\n",
    "Iteration 54; Predictions: 2.11056717045; actual: 2.0\n",
    "Iteration 55; Predictions: 2.01297288001; actual: 1.0\n",
    "Iteration 56; Predictions: 1.76846145146; actual: 3.0\n",
    "Iteration 57; Predictions: 1.88682307817; actual: 2.0\n",
    "Iteration 58; Predictions: 1.76397964809; actual: 2.0\n",
    "Iteration 59; Predictions: 1.7184026813; actual: 4.0\n",
    "Iteration 60; Predictions: 2.08709961768; actual: 4.0\n",
    "Iteration 61; Predictions: 2.17914615062; actual: 3.0\n",
    "Iteration 62; Predictions: -0.140174332917; actual: 2.0\n",
    "Iteration 63; Predictions: 1.26121404055; actual: 2.0\n",
    "Iteration 64; Predictions: 0.301914109078; actual: 1.0\n",
    "Iteration 65; Predictions: 0.919494131771; actual: 3.0\n",
    "Iteration 66; Predictions: 0.985797251757; actual: 1.0\n",
    "Iteration 67; Predictions: 1.134861697; actual: 1.0\n",
    "R^2: 0.257591460265, p-value: 9.98754155143e-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WND5 delta WOMAC Train class sizes : 67\n",
    "Features          : 100\n",
    "Iterations        : 68\n",
    "Iteration 0; Predictions: 0.550663064546; actual: 0.0\n",
    "Iteration 1; Predictions: 7.2671354061; actual: 0.0\n",
    "Iteration 2; Predictions: 0.274108186227; actual: 0.0\n",
    "Iteration 3; Predictions: 0.632047365581; actual: 0.0\n",
    "Iteration 4; Predictions: 0.178626743462; actual: 0.0\n",
    "Iteration 5; Predictions: 0.178626743462; actual: 0.0\n",
    "Iteration 6; Predictions: 25.1438341205; actual: 0.0\n",
    "Iteration 7; Predictions: 35.5280094506; actual: 0.0\n",
    "Iteration 8; Predictions: 2.06506201178; actual: 0.0\n",
    "Iteration 9; Predictions: 27.4646026485; actual: 0.0\n",
    "Iteration 10; Predictions: 14.1655458335; actual: 0.0\n",
    "Iteration 11; Predictions: 19.6888266242; actual: 0.0\n",
    "Iteration 12; Predictions: 16.4334922932; actual: 0.0\n",
    "Iteration 13; Predictions: 2.44438944219; actual: 0.0\n",
    "Iteration 14; Predictions: 33.9744018127; actual: 0.0\n",
    "Iteration 15; Predictions: 16.9732729029; actual: 0.0\n",
    "Iteration 16; Predictions: 13.7804112225; actual: 0.0\n",
    "Iteration 17; Predictions: 13.6669442444; actual: 0.0\n",
    "Iteration 18; Predictions: 35.5128726696; actual: 0.0\n",
    "Iteration 19; Predictions: 11.3210857604; actual: 0.0\n",
    "Iteration 20; Predictions: 11.0214890267; actual: 0.0\n",
    "Iteration 21; Predictions: 24.2227155379; actual: 0.0\n",
    "Iteration 22; Predictions: 8.73011569592; actual: 0.0\n",
    "Iteration 23; Predictions: 10.0722706507; actual: 0.0\n",
    "Iteration 24; Predictions: 3.77052707328; actual: 0.0\n",
    "Iteration 25; Predictions: 5.2635304292; actual: 0.0\n",
    "Iteration 26; Predictions: 40.0846065637; actual: 0.0\n",
    "Iteration 27; Predictions: 3.20975883345; actual: 0.0\n",
    "Iteration 28; Predictions: 24.7852407131; actual: 12.0\n",
    "Iteration 29; Predictions: 13.4405390902; actual: 37.1\n",
    "Iteration 30; Predictions: 29.7503398124; actual: 13.0\n",
    "Iteration 31; Predictions: 22.7688348051; actual: 13.0\n",
    "Iteration 32; Predictions: 29.6965443914; actual: 27.0\n",
    "Iteration 33; Predictions: 17.5055429439; actual: 41.0\n",
    "Iteration 34; Predictions: 20.1061784568; actual: 11.0\n",
    "Iteration 35; Predictions: 8.05524450775; actual: 18.0\n",
    "Iteration 36; Predictions: 23.1863832271; actual: 33.4\n",
    "Iteration 37; Predictions: 21.8517422054; actual: 25.5\n",
    "Iteration 38; Predictions: 13.6073000508; actual: 17.8\n",
    "Iteration 39; Predictions: 34.626944017; actual: 20.0\n",
    "Iteration 40; Predictions: 21.0527406559; actual: 22.0\n",
    "Iteration 41; Predictions: 39.2497061197; actual: 35.6\n",
    "Iteration 42; Predictions: 26.838644646; actual: 30.0\n",
    "Iteration 43; Predictions: 16.7659823429; actual: 19.0\n",
    "Iteration 44; Predictions: 21.5859991669; actual: 20.1\n",
    "Iteration 45; Predictions: 34.4053295525; actual: 35.1\n",
    "Iteration 46; Predictions: 17.9078259635; actual: 30.2\n",
    "Iteration 47; Predictions: 33.2145976195; actual: 17.0\n",
    "Iteration 48; Predictions: 26.44719679; actual: 27.1\n",
    "Iteration 49; Predictions: 14.7076266915; actual: 39.7\n",
    "Iteration 50; Predictions: 17.9959655238; actual: 12.2\n",
    "Iteration 51; Predictions: 25.0150402999; actual: 18.0\n",
    "Iteration 52; Predictions: 28.9949180524; actual: 24.3\n",
    "Iteration 53; Predictions: 34.846669773; actual: 33.0\n",
    "Iteration 54; Predictions: 25.847125744; actual: 24.2\n",
    "Iteration 55; Predictions: 30.6661627183; actual: 17.7\n",
    "Iteration 56; Predictions: 18.9661221141; actual: 40.0\n",
    "Iteration 57; Predictions: 23.1326172999; actual: 24.0\n",
    "Iteration 58; Predictions: 27.3665024494; actual: 22.0\n",
    "Iteration 59; Predictions: 32.3741422247; actual: 49.0\n",
    "Iteration 60; Predictions: 28.3427363853; actual: 43.7\n",
    "Iteration 61; Predictions: 13.4068028688; actual: 40.0\n",
    "Iteration 62; Predictions: 0.000697327865554; actual: 24.0\n",
    "Iteration 63; Predictions: 19.8921839437; actual: 23.0\n",
    "Iteration 64; Predictions: 12.2066980016; actual: 18.0\n",
    "Iteration 65; Predictions: 16.0112884411; actual: 35.6\n",
    "Iteration 66; Predictions: 20.3083487882; actual: 14.0\n",
    "Iteration 67; Predictions: 17.8671100694; actual: 19.3\n",
    "R^2: 0.140226297076, p-value: 0.00165514611213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WND5 500 features delta womac\n",
    "Train class sizes : 39\n",
    "Features          : 500\n",
    "Iterations        : 40\n",
    "Iteration 0; Predictions: 23.5493950505; actual: 12.0\n",
    "Iteration 1; Predictions: 27.6500479383; actual: 37.1\n",
    "Iteration 2; Predictions: 38.4348340927; actual: 13.0\n",
    "Iteration 3; Predictions: 31.0363263112; actual: 13.0\n",
    "Iteration 4; Predictions: 23.337795507; actual: 27.0\n",
    "Iteration 5; Predictions: 23.6231138917; actual: 41.0\n",
    "Iteration 6; Predictions: 26.023003065; actual: 11.0\n",
    "Iteration 7; Predictions: 25.2555316193; actual: 18.0\n",
    "Iteration 8; Predictions: 24.0168380751; actual: 33.4\n",
    "Iteration 9; Predictions: 27.0372672733; actual: 25.5\n",
    "Iteration 10; Predictions: 25.0138741919; actual: 17.8\n",
    "Iteration 11; Predictions: 28.128433289; actual: 20.0\n",
    "Iteration 12; Predictions: 26.1963453511; actual: 22.0\n",
    "Iteration 13; Predictions: 22.1178662056; actual: 35.6\n",
    "Iteration 14; Predictions: 22.118865088; actual: 30.0\n",
    "Iteration 15; Predictions: 23.0162726147; actual: 19.0\n",
    "Iteration 16; Predictions: 23.9536293032; actual: 20.1\n",
    "Iteration 17; Predictions: 22.9287235682; actual: 35.1\n",
    "Iteration 18; Predictions: 13.048607787; actual: 30.2\n",
    "Iteration 19; Predictions: 23.5562568261; actual: 17.0\n",
    "Iteration 20; Predictions: 23.9572419809; actual: 27.1\n",
    "Iteration 21; Predictions: 21.3257338343; actual: 39.7\n",
    "Iteration 22; Predictions: 18.4507984255; actual: 12.2\n",
    "Iteration 23; Predictions: 20.6600242927; actual: 18.0\n",
    "Iteration 24; Predictions: 25.4691502696; actual: 24.3\n",
    "Iteration 25; Predictions: 22.0820529388; actual: 33.0\n",
    "Iteration 26; Predictions: 18.4503276698; actual: 24.2\n",
    "Iteration 27; Predictions: 25.2433968851; actual: 17.7\n",
    "Iteration 28; Predictions: 26.2540714484; actual: 40.0\n",
    "Iteration 29; Predictions: 15.6255011585; actual: 24.0\n",
    "Iteration 30; Predictions: 27.4590350288; actual: 22.0\n",
    "Iteration 31; Predictions: 24.6286476006; actual: 49.0\n",
    "Iteration 32; Predictions: 22.7251714305; actual: 43.7\n",
    "Iteration 33; Predictions: 13.5349802037; actual: 40.0\n",
    "Iteration 34; Predictions: 23.2613810154; actual: 24.0\n",
    "Iteration 35; Predictions: 21.8831333067; actual: 23.0\n",
    "Iteration 36; Predictions: 16.5313387488; actual: 18.0\n",
    "Iteration 37; Predictions: 25.2655483197; actual: 35.6\n",
    "Iteration 38; Predictions: 23.4115370106; actual: 14.0\n",
    "Iteration 39; Predictions: 19.6916067552; actual: 19.3\n",
    "R^2: 0.0407714320522, p-value: 0.21149226021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WND5 discrete WOMAC score\n",
    "Train class sizes : 67\n",
    "Features          : 500\n",
    "Iterations        : 68\n",
    "Iteration 0; Predictions: 2.04666666667; actual: 0.0\n",
    "Iteration 1; Predictions: 4.46; actual: 0.0\n",
    "Iteration 2; Predictions: 7.46833333333; actual: 1.0\n",
    "Iteration 3; Predictions: 4.32666666667; actual: 0.0\n",
    "Iteration 4; Predictions: 1.39333333333; actual: 0.0\n",
    "Iteration 5; Predictions: 2.35666666667; actual: 1.0\n",
    "Iteration 6; Predictions: 6.28222222222; actual: 0.0\n",
    "Iteration 7; Predictions: 20.0966666667; actual: 0.0\n",
    "Iteration 8; Predictions: 0.833333333333; actual: 2.0\n",
    "Iteration 9; Predictions: 13.76; actual: 0.0\n",
    "Iteration 10; Predictions: 10.1666666667; actual: 0.0\n",
    "Iteration 11; Predictions: 22.67; actual: 0.0\n",
    "Iteration 12; Predictions: 7.29; actual: 0.0\n",
    "Iteration 13; Predictions: 5.45555555556; actual: 0.0\n",
    "Iteration 14; Predictions: 35.3633333333; actual: 0.0\n",
    "Iteration 15; Predictions: 27.3833333333; actual: 0.0\n",
    "Iteration 16; Predictions: 9.80888888889; actual: 0.0\n",
    "Iteration 17; Predictions: 16.4533333333; actual: 0.0\n",
    "Iteration 18; Predictions: 24.18; actual: 1.0\n",
    "Iteration 19; Predictions: 26.1366666667; actual: 0.0\n",
    "Iteration 20; Predictions: 6.32; actual: 0.0\n",
    "Iteration 21; Predictions: 21.9266666667; actual: 0.0\n",
    "Iteration 22; Predictions: 16.6933333333; actual: 0.0\n",
    "Iteration 23; Predictions: 11.7466666667; actual: 0.0\n",
    "Iteration 24; Predictions: 9.72055555556; actual: 0.0\n",
    "Iteration 25; Predictions: 17.3666666667; actual: 0.0\n",
    "Iteration 26; Predictions: 11.2066666667; actual: 0.0\n",
    "Iteration 27; Predictions: 8.54666666667; actual: 0.0\n",
    "Iteration 28; Predictions: 24.7033333333; actual: 14.0\n",
    "Iteration 29; Predictions: 4.97; actual: 40.1\n",
    "Iteration 30; Predictions: 34.47; actual: 13.0\n",
    "Iteration 31; Predictions: 24.7733333333; actual: 13.0\n",
    "Iteration 32; Predictions: 27.9266666667; actual: 35.0\n",
    "Iteration 33; Predictions: 8.77666666667; actual: 43.0\n",
    "Iteration 34; Predictions: 26.2366666667; actual: 19.0\n",
    "Iteration 35; Predictions: 16.2966666667; actual: 22.0\n",
    "Iteration 36; Predictions: 33.5166666667; actual: 41.4\n",
    "Iteration 37; Predictions: 11.6966666667; actual: 33.5\n",
    "Iteration 38; Predictions: 7.48444444444; actual: 17.8\n",
    "Iteration 39; Predictions: 25.9866666667; actual: 20.0\n",
    "Iteration 40; Predictions: 24.74; actual: 22.0\n",
    "Iteration 41; Predictions: 26.33; actual: 35.6\n",
    "Iteration 42; Predictions: 23.2633333333; actual: 35.0\n",
    "Iteration 43; Predictions: 30.1166666667; actual: 27.0\n",
    "Iteration 44; Predictions: 27.2233333333; actual: 25.1\n",
    "Iteration 45; Predictions: 23.21; actual: 41.1\n",
    "Iteration 46; Predictions: 16.5; actual: 30.2\n",
    "Iteration 47; Predictions: 29.99; actual: 19.0\n",
    "Iteration 48; Predictions: 23.8366666667; actual: 28.1\n",
    "Iteration 49; Predictions: 15.1433333333; actual: 39.7\n",
    "Iteration 50; Predictions: 15.8577777778; actual: 15.4\n",
    "Iteration 51; Predictions: 25.6666666667; actual: 21.0\n",
    "Iteration 52; Predictions: 27.92; actual: 30.3\n",
    "Iteration 53; Predictions: 19.95; actual: 36.1\n",
    "Iteration 54; Predictions: 16.7866666667; actual: 28.4\n",
    "Iteration 55; Predictions: 21.0133333333; actual: 19.7\n",
    "Iteration 56; Predictions: 22.13; actual: 42.0\n",
    "Iteration 57; Predictions: 26.2833333333; actual: 31.1\n",
    "Iteration 58; Predictions: 29.0133333333; actual: 30.4\n",
    "Iteration 59; Predictions: 20.26; actual: 53.0\n",
    "Iteration 60; Predictions: 26.6766666667; actual: 48.8\n",
    "Iteration 61; Predictions: 17.9033333333; actual: 44.0\n",
    "Iteration 62; Predictions: 6.05777777778; actual: 24.0\n",
    "Iteration 63; Predictions: 3.655; actual: 30.0\n",
    "Iteration 64; Predictions: 12.42; actual: 24.0\n",
    "Iteration 65; Predictions: 19.9966666667; actual: 44.6\n",
    "Iteration 66; Predictions: 28.4766666667; actual: 24.0\n",
    "Iteration 67; Predictions: 9.73; actual: 19.3\n",
    "R^2: 0.126804735303, p-value: 0.00287906358515"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
